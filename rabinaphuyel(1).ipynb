{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0714 14:12:25.082078 140587591059200 deprecation_wrapper.py:119] From /home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/cleverhans/utils_tf.py:341: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "classifier and attacker\n",
    "dataset: mnist\n",
    "\"\"\" \n",
    "# ---------------------\n",
    "# import required packages\n",
    "# ---------------------\n",
    "from __future__ import division, absolute_import, print_function\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import time\n",
    "\n",
    "from cleverhans.evaluation import batch_eval\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tf.set_random_seed(1000)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.34 ms\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------\n",
    "# Configuration for the experiment\n",
    "# ------------------------------------\n",
    "# parameters (model)\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# parameters (dataset)\n",
    "IMG_ROW = 28\n",
    "IMG_COL = 28\n",
    "VAL_RATE = 0.2\n",
    "\n",
    "# parameters (fgsm)\n",
    "eps = 0.25\n",
    "\n",
    "\"\"\"\n",
    "Datasets used to train the models,\n",
    "Each item stands for one type of transformation being applied on the dataset.\n",
    "Specifically, 'clean' means the original dataset, no transformation being applied,\n",
    "and each the rest stands for the transformation being applied on the clean dataset.\n",
    "e.g., 'rotate90' means that each image was rotated 90 deg.\n",
    "\"\"\"\n",
    "# -----------------------------------\n",
    "# Your task:\n",
    "# Please complete this array, adding the transformations of interest.\n",
    "# Please note that the transformations being added here\n",
    "# should be the same you added in the transform function.\n",
    "# -----------------------------------\n",
    "M = ['clean', 'rotate90', 'rotate180', 'rotate270', 'erosion', 'dilation', 'gradient']\n",
    "# a walkaround for error of not able to save trained model:\n",
    "# training models one by one\n",
    "#M = ['rotate90'] \n",
    "\n",
    "# -----------------------------------\n",
    "# Your task ends\n",
    "# -----------------------------------\n",
    "\n",
    "\"\"\"\n",
    "Adversarial examples generation algorithms.\n",
    "\"\"\"\n",
    "attacks = ['fgsm'] #, 'jsma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.99 ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load data\n",
    "\"\"\"\n",
    "def load_mnist():\n",
    "    \"\"\"\n",
    "    Load and process training set and test set\n",
    "    \"\"\"\n",
    "    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "    X_train = X_train.reshape(-1, IMG_ROW, IMG_COL, 1)\n",
    "    X_test = X_test.reshape(-1, IMG_ROW, IMG_COL, 1)\n",
    "    # cast pixels to floats, normalize to [0, 1] range\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "\n",
    "    # one-hot-encode the labels\n",
    "    Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "    Y_test = np_utils.to_categorical(Y_test, 10)\n",
    "    \n",
    "    print(\"Dataset summary:\")\n",
    "    print(\"Train set: {}, {}\".format(X_train.shape, Y_train.shape))\n",
    "    print(\"Test set: {}, {}\".format(X_test.shape, Y_test.shape))\n",
    "    \n",
    "    return (X_train, Y_train), (X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.53 ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Define model structures for some datasets.\n",
    "\"\"\"\n",
    "def cnn():\n",
    "    \"\"\"\n",
    "    Returns the appropriate Keras model.\n",
    "    :return: The model; a Keras 'Sequential' instance.\n",
    "    \"\"\"\n",
    "    # MNIST model\n",
    "    struct = [\n",
    "        layers.Conv2D(32, (3, 3), input_shape = (IMG_ROW, IMG_COL, 1)),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3)),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64 * 64),\n",
    "        layers.Dropout(rate = 0.4),\n",
    "        layers.Dense(10),\n",
    "        layers.Activation('softmax')\n",
    "    ]\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    for layer in struct:\n",
    "        model.add(layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.7 ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training a model\n",
    "\"\"\"\n",
    "def train(X, Y, model_name='mnist_cnn_clean.model'):\n",
    "    \"\"\"\n",
    "    Train a model over given training set,\n",
    "    then save the trained model.\n",
    "    :param: model - the keras model to train\n",
    "    :param: train_set - Tuple of the training set, includes training samples and corresponding desired labels.\n",
    "    :param: val_set - Tuple of the validation set, includes samples and desired labels.\n",
    "    :param: model_name - the name used to save the trained model.\n",
    "    :return: na\n",
    "    \"\"\"\n",
    "    nb_train = int(len(X) * VAL_RATE)\n",
    "    train_samples = X[:-nb_train]\n",
    "    train_classes = Y[:-nb_train]\n",
    "    val_samples = X[-nb_train:]\n",
    "    val_classes = Y[-nb_train:]\n",
    "    \n",
    "    model = cnn()\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', \n",
    "                  optimizer = 'adam', metrics = ['accuracy'])\n",
    "    \n",
    "    \n",
    "    # Train the model\n",
    "    print(\"Training {}...\".format(model_name))\n",
    "    model.fit(train_samples, train_classes, epochs = 1,\n",
    "              batch_size = BATCH_SIZE, shuffle = True,\n",
    "              verbose = 1, validation_data = (val_samples, val_classes))\n",
    "     \n",
    "    # Save the model\n",
    "    #model.save(\"data/{}\".format(model_name))\n",
    "    models.save_model(model, \"data/{}\".format(model_name))\n",
    "    del model\n",
    "    \n",
    "    print(\"Trained model has been saved to data/{}\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.92 ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implement algorithms generating adversarial examples\n",
    "\"\"\"\n",
    "def fgsm(x, prediction, eps, y = None):\n",
    "    '''\n",
    "    Define the symbolic FGSM fitting tf framework\n",
    "    '''\n",
    "    if y is None:\n",
    "        y = tf.cast(tf.equal(prediction, \n",
    "                                tf.reduce_max(prediction, 1, keepdims = True)), tf.float32)\n",
    "        \n",
    "    y /= tf.reduce_sum(y, 1, keepdims = True)\n",
    "    \n",
    "    logits, = prediction.op.inputs\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = y))\n",
    "\n",
    "    grad, = tf.gradients(loss, x)\n",
    "    perturbation = eps * tf.sign(grad)\n",
    "    adv_sample = tf.stop_gradient(x + perturbation)\n",
    "    \n",
    "    return adv_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 25.3 ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Crafting adversarial examples.\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "def generate_adversarial(model_name, X, Y, attack_approach):\n",
    "    \"\"\"\n",
    "    Craft and save adversarial examples.\n",
    "    :param: model_name - the name of the target model\n",
    "    :param: X\n",
    "    :param: Y\n",
    "    :param: attack_approach - adversarial example generation algorithm to use\n",
    "    :param: adv_file_name - the file name used to save the generated adversarial exmaples\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        K.set_session(sess)\n",
    "        K.set_learning_phase(0)\n",
    "        \n",
    "        # define tf placeholders and operations\n",
    "        x = tf.placeholder(tf.float32, shape = (None,) + X.shape[1:])\n",
    "        y = tf.placeholder(tf.float32, shape = (None,) + Y.shape[1:])\n",
    "\n",
    "        # load model\n",
    "        model = load_model(\"data/{}\".format(model_name))\n",
    "        adv_file_name = model_name.split('.')[0]\n",
    "\n",
    "        # model accuracy\n",
    "        _, acc_original = model.evaluate(X, Y, batch_size = BATCH_SIZE, verbose = 0)\n",
    "        print('test acc (on original): {}'.format(acc_original))\n",
    "\n",
    "        if attack_approach == 'fgsm':\n",
    "            adv_file_name = '{}_{}_eps{}.npy'.format(adv_file_name, attack_approach, int(eps * 100))\n",
    "\n",
    "            # symbolic fgsm\n",
    "            x_adv = fgsm(x, model(x), eps = eps, y = y)\n",
    "\n",
    "            # craft adversarial examples\n",
    "            X_adv, = batch_eval(sess, [x, y], [x_adv], [X, Y], batch_size = BATCH_SIZE)\n",
    "        elif attack_approach == 'jsma':\n",
    "            raise NotImplementedError('Not ready yet.')\n",
    "        else:\n",
    "            raise ValueError('{} is not supported.'.format(attack_approach))\n",
    "\n",
    "        # test accuracy on adversarial examples\n",
    "        _, acc_adv = model.evaluate(X_adv, Y, batch_size = BATCH_SIZE, verbose = 0)\n",
    "        print ('test acc (on adversarial): {} - (epsilon: {})'.format(acc_adv, eps))\n",
    "        \n",
    "        print('adv:', X.shape, X_adv.shape, Y.shape)\n",
    "                \n",
    "        # save the generated adversarial examples\n",
    "        np.save(\"data/orig_{}\".format(adv_file_name), X)\n",
    "        np.save(\"data/adv_{}\".format(adv_file_name), X_adv)\n",
    "        np.save(\"data/label_{}\".format(adv_file_name), Y)\n",
    "        print(\"adversarial examples were generated and saved to data/{}\".format(adv_file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 80.3 ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Apply standard transformation on given dataset.\n",
    "\"\"\"\n",
    "def transform(original_images, IMG_ROW, IMG_COL, transformation):\n",
    "    \"\"\"\n",
    "    Apply standard transformation on given dataset.\n",
    "    :param: original_images - the images to applied transformations on.\n",
    "    :param: transformation - the standard transformation to apply.\n",
    "    :return: the transformed dataset.\n",
    "    \"\"\"\n",
    "    trans_matrix = None\n",
    "    \n",
    "    transformed_images = []\n",
    "    \n",
    "    if transformation == 'rotate90':\n",
    "        angle90 = 90\n",
    "        scale = 1.0\n",
    "        center = (IMG_ROW / 2, IMG_COL / 2)\n",
    "        \n",
    "        trans_matrix = cv2.getRotationMatrix2D(center, angle90, scale)\n",
    "    elif transformation == 'rotate180':\n",
    "        angle180 = 180\n",
    "        scale = 1.0\n",
    "        center = (IMG_ROW / 2, IMG_COL / 2)\n",
    "        \n",
    "        trans_matrix = cv2.getRotationMatrix2D(center, angle180, scale)\n",
    "    elif transformation == 'rotate270':\n",
    "        angle270 = 270\n",
    "        scale = 1.0\n",
    "        center = (IMG_ROW / 2, IMG_COL / 2)\n",
    "        \n",
    "        trans_matrix = cv2.getRotationMatrix2D(center, angle270, scale)\n",
    "        \n",
    "    elif transformation == 'erosion':\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        center = (IMG_ROW/2 , IMG_COL/2)\n",
    "        \n",
    "        trans_matrix = cv2.erode(kernel, center, iterations = 1)\n",
    "    elif transformation == 'dilation':\n",
    "        center = (IMG_ROW/2, IMG_COL/2)\n",
    "        kernel = np.ones((5, 5), np.uint8);\n",
    "        \n",
    "        trans_matrix = cv2.dilate(kernel,center,iterations = 1)\n",
    "        \n",
    "    elif transformation == 'gradient':\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        center = (IMG_ROW/2, IMG_COL/2)\n",
    "        trans_matrix = cv2.morphologyEx(cv2.MORPH_GRADIENT, center, kernel)\n",
    "    '''elif transformation == 'Affine:\n",
    "        center = (IMG_ROW / 2, IMG_COL / 2)\n",
    "        pts = ([[1,0,100],[0,1,50]])\n",
    "        #dst = cv2.getAffineTransform(pts)\n",
    "        trans_matrix = cv2.warpAffine(pts, center)'''\n",
    "   \n",
    "        \n",
    "    # ----------------------------\n",
    "    # Your codes start here\n",
    "    # ----------------------------\n",
    "    \"\"\"\n",
    "    Please take care the rest transformation types here:\n",
    "    1. Each type per elif statement,\n",
    "    for example, elif transformation == 'rotate180':\n",
    "    2. Define transformation matrix (please assign to variable 'trans_matrix')\n",
    "    Please take care of the corresponding parameters for each transformation type, respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "    # ----------------------------\n",
    "    # Your codes end\n",
    "    # ----------------------------\n",
    "#     else:\n",
    "#         raise ValueError('{} is not supported.'.format(transformation))\n",
    "    \n",
    "    # applying an affine transformation over the dataset\n",
    "    transformed_images = np.zeros_like(original_images)\n",
    "    for i in range(original_images.shape[0]):\n",
    "        transformed_images[i] = np.expand_dims(cv2.warpAffine(original_images[i], trans_matrix, \n",
    "                                                              (IMG_COL, IMG_ROW)), axis = 2)\n",
    "\n",
    "        # for debugging\n",
    "        '''for i in range(5):\n",
    "            cv2.imshow('clean image', X_train[i].reshape(IMG_ROW, IMG_COL))\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "            cv2.imshow(transformation, transformed_images[i])\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()'''\n",
    "    print('Applied transformation {}.'.format(transformation))\n",
    "    return transformed_images\n",
    "\n",
    "\"\"\"\n",
    "Evaluate a model\n",
    "\"\"\"\n",
    "def evaluate(model_name, X, Y):\n",
    "    \"\"\"\n",
    "    Evaluate given model.\n",
    "    :param: model - the model to evaluate.\n",
    "    :param: X - the test set.\n",
    "    :param: Y - the desired labels associated with test examples.\n",
    "    :return: test accuracy, \n",
    "            average confidence for correctly classified examples, \n",
    "            average confidence for misclassified examples.\n",
    "    \"\"\"\n",
    "    correct_cnt = 0\n",
    "    nb_examples = 0\n",
    "    \n",
    "    test_acc = 0.\n",
    "    conf = 0.\n",
    "    conf_misclassified = 0.\n",
    "    \n",
    "    model = load_model('data/{}'.format(model_name))\n",
    "    \n",
    "    pred_probs = model.predict(X, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # iterate over test set\n",
    "    for pred_prob, true_prob in zip(pred_probs, Y):\n",
    "        nb_examples += 1\n",
    "        \n",
    "        pred_label = np.argmax(pred_prob)\n",
    "        true_label = np.argmax(true_prob)\n",
    "        \n",
    "        if (pred_label == true_label):\n",
    "            correct_cnt += 1\n",
    "            conf += np.max(pred_prob)\n",
    "        else:\n",
    "            conf_misclassified += np.max(pred_prob)\n",
    "    \n",
    "    # test accuracy\n",
    "    test_acc = (1.0 * correct_cnt) / nb_examples\n",
    "    \n",
    "    # average confidece for correctly classified examples\n",
    "    avg_conf = conf / correct_cnt\n",
    "    \n",
    "    # average confidence for misclassified examples\n",
    "    avg_conf_misclassified = conf_misclassified / (nb_examples - correct_cnt)\n",
    "    \n",
    "    return test_acc, avg_conf, avg_conf_misclassified    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.2 ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Evaluate an attack\n",
    "\n",
    "\"\"\"\n",
    "def evaluate_attack(model_name, adv_file_name, transformation):\n",
    "    \"\"\"\n",
    "    Evaluate attack approach\n",
    "    :param: model_name - name of the target model.\n",
    "    :param: X - the original test set.\n",
    "    :param: Y - the desired labels associated with test examples.\n",
    "    :param: adv_file_name - name of the adversarial example file.\n",
    "    :return: test accuracy,\n",
    "            average confidence,\n",
    "            error rate\n",
    "    \"\"\"\n",
    "    # load model\n",
    "    model = load_model('data/{}'.format(model_name))\n",
    "    \n",
    "    cnt_correct = 0\n",
    "    nb_legitimates = 0\n",
    "    cnt_miss = 0\n",
    "    \n",
    "    test_acc = 0.\n",
    "    conf = 0.\n",
    "    err_rate = 0.\n",
    "    \n",
    "    X = np.load('data/orig_{}'.format(adv_file_name))\n",
    "    X_adv = np.load('data/adv_{}'.format(adv_file_name))\n",
    "    Y = np.load('data/label_{}'.format(adv_file_name))\n",
    "    \n",
    "    print(X.shape, X_adv.shape, Y.shape)\n",
    "    \n",
    "    if transformation != 'clean':\n",
    "        X = transform(X, IMG_ROW, IMG_COL, transformation)\n",
    "        X_adv = transform(X_adv, IMG_ROW, IMG_COL, transformation)\n",
    "    \n",
    "    pred_probs = model.predict(X, batch_size=BATCH_SIZE)\n",
    "    pred_probs_adv = model.predict(X_adv, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    _, acc_original = model.evaluate(X, Y, batch_size = BATCH_SIZE, verbose = 0)\n",
    "    _, acc_adv = model.evaluate(X_adv, Y, batch_size = BATCH_SIZE, verbose = 0)\n",
    "    \n",
    "    print(acc_original, acc_adv)\n",
    "    \n",
    "    for pred_prob, pred_prob_adv, true_prob in zip(pred_probs, pred_probs_adv, Y):\n",
    "        pred_label = np.argmax(pred_prob)\n",
    "        pred_label_adv = np.argmax(pred_prob_adv)\n",
    "        true_label = np.argmax(true_prob)\n",
    "        \n",
    "        if (pred_label == true_label):\n",
    "            nb_legitimates += 1\n",
    "            if (pred_label_adv != pred_label):\n",
    "                conf += np.max(pred_prob_adv)\n",
    "                cnt_miss += 1\n",
    "            else:\n",
    "                cnt_correct += 1\n",
    "              \n",
    "    # error rate\n",
    "    miss_original = 1 - acc_original\n",
    "    miss_adv = 1 - acc_adv\n",
    "    err_rate = miss_adv - miss_original\n",
    "    \n",
    "    # average confidece for examples successfully attacked\n",
    "    avg_conf = conf / cnt_miss\n",
    "        \n",
    "    return acc_original, acc_adv, err_rate, avg_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.99 ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training models: One over each transformed dataset.\n",
    "Then evaluating each trained models.\n",
    "\"\"\"\n",
    "def training():\n",
    "    # training models\n",
    "    for trans in tqdm(M):\n",
    "        model_name = 'mnist_cnn_{}.h5'.format(trans)\n",
    "        print(\"Training model {}...\".format(model_name))\n",
    "        \n",
    "        (X_train, Y_train), _ = load_mnist()\n",
    "\n",
    "        if trans != 'clean':\n",
    "            # transform data\n",
    "            X_train = transform(X_train, IMG_ROW, IMG_COL, trans)\n",
    "        \n",
    "        # train the model\n",
    "        train(X_train, Y_train, model_name=model_name)\n",
    "        \n",
    "        print(\"---------------------------\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.39 ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Crafting adversarial examples.\n",
    "\"\"\"\n",
    "def crafting_adversarial_examples():\n",
    "    (X_train, Y_train), (X_test, Y_test) = load_mnist()\n",
    "\n",
    "    # generate_adversarial(model_name, X, Y, attack_approach):\n",
    "\n",
    "    for attack in tqdm(attacks):\n",
    "        #generate_adversarial(model_name = 'mnist_cnn_clean.h5', X_train, Y_train, attack)\n",
    "        generate_adversarial('mnist_cnn_clean.h5', X_test, Y_test, attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.68 ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Evaluating adversarial attacks.\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "def evaluating_attacks():\n",
    "    acc_models = []\n",
    "    acc_advs = []\n",
    "    ave_confs = []\n",
    "    error_rates = []\n",
    "    \n",
    "    # def evaluate_attack(model_name, X, Y, adv_file_name):\n",
    "    for attack in tqdm(attacks):\n",
    "        adv_file_name = 'mnist_cnn_clean_{}_eps{}.npy'.format(attack, int(eps * 100))\n",
    "\n",
    "        for trans in tqdm(M):\n",
    "            model_name = 'mnist_cnn_{}.h5'.format(trans)\n",
    "            acc, acc_adv, err_rate, conf = evaluate_attack(model_name, adv_file_name, trans)\n",
    "\n",
    "            acc_models.append(acc)\n",
    "            acc_advs.append(acc_adv)\n",
    "            ave_confs.append(conf)\n",
    "            error_rates.append(err_rate)\n",
    "\n",
    "    return acc_models, acc_advs, error_rates, ave_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.76 ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Evaluate models\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "def evaluating():\n",
    "    test_accuracies = []\n",
    "    ave_confs = []\n",
    "    ave_confs_misclassified = []\n",
    "    \n",
    "    # training models\n",
    "    for trans in tqdm(M):\n",
    "        model_name = 'mnist_cnn_{}.h5'.format(trans)\n",
    "        print(\"Evaluating model {}...\".format(model_name))\n",
    "        \n",
    "        _, (X_test, Y_test) = load_mnist()\n",
    "\n",
    "        if trans != 'clean':\n",
    "            # transform data\n",
    "            X_test = transform(X_test, IMG_ROW, IMG_COL, trans)\n",
    "         \n",
    "        # evaluate trained model\n",
    "        acc, conf, conf_misclassified = evaluate(model_name, X_test, Y_test)\n",
    "\n",
    "        test_accuracies.append(acc)\n",
    "        ave_confs.append(conf)\n",
    "        ave_confs_misclassified.append(conf_misclassified)\n",
    "\n",
    "    return test_accuracies, ave_confs, ave_confs_misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.29 ms\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Automating experiments.\n",
    "# 1. train and save models\n",
    "# \n",
    "# You only need to run this once per model structure, dataset.\n",
    "# ---------------------------\n",
    "#training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]W0714 14:12:25.825325 140587591059200 deprecation.py:506] From /home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0714 14:12:25.827725 140587591059200 deprecation.py:506] From /home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0714 14:12:25.830027 140587591059200 deprecation.py:506] From /home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset summary:\n",
      "Train set: (60000, 28, 28, 1), (60000, 10)\n",
      "Test set: (10000, 28, 28, 1), (10000, 10)\n",
      "test acc (on original): 0.982500016689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 1/1 [00:07<00:00,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc (on adversarial): 0.0518000014126 - (epsilon: 0.25)\n",
      "adv: (10000, 28, 28, 1) (10000, 28, 28, 1) (10000, 10)\n",
      "adversarial examples were generated and saved to data/mnist_cnn_clean_fgsm_eps25.npy\n",
      "time: 7.68 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Automating experiments.\n",
    "# 2. craft and save adversarial examples\n",
    "#\n",
    "# You only need to run this once per targeted model, attack approach.\n",
    "# ---------------------------\n",
    "crafting_adversarial_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model mnist_cnn_clean.h5...\n",
      "Dataset summary:\n",
      "Train set: (60000, 28, 28, 1), (60000, 10)\n",
      "Test set: (10000, 28, 28, 1), (10000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.') in <bound method _Callable.__del__ of <tensorflow.python.client.session._Callable object at 0x7fdcbfcf6510>> ignored\n",
      "W0714 14:12:33.796168 140587591059200 deprecation.py:323] From /home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      " 14%|█▍        | 1/7 [00:02<00:14,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model mnist_cnn_rotate90.h5...\n",
      "Dataset summary:\n",
      "Train set: (60000, 28, 28, 1), (60000, 10)\n",
      "Test set: (10000, 28, 28, 1), (10000, 10)\n",
      "Applied transformation rotate90.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 2/7 [00:05<00:12,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model mnist_cnn_rotate180.h5...\n",
      "Dataset summary:\n",
      "Train set: (60000, 28, 28, 1), (60000, 10)\n",
      "Test set: (10000, 28, 28, 1), (10000, 10)\n",
      "Applied transformation rotate180.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 3/7 [00:07<00:10,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model mnist_cnn_rotate270.h5...\n",
      "Dataset summary:\n",
      "Train set: (60000, 28, 28, 1), (60000, 10)\n",
      "Test set: (10000, 28, 28, 1), (10000, 10)\n",
      "Applied transformation rotate270.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 4/7 [00:11<00:08,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model mnist_cnn_erosion.h5...\n",
      "Dataset summary:\n",
      "Train set: (60000, 28, 28, 1), (60000, 10)\n",
      "Test set: (10000, 28, 28, 1), (10000, 10)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) /tmp/build/80754af9/opencv-suite_1535558553474/work/modules/imgproc/src/imgwarp.cpp:2619: error: (-215:Assertion failed) (M0.type() == 5 || M0.type() == 6) && M0.rows == 2 && M0.cols == 3 in function 'warpAffine'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a008d9037b39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ---------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfs_misclassified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# print reports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-08901369a88c>\u001b[0m in \u001b[0;36mevaluating\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrans\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'clean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# transform data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_ROW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_COL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# evaluate trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d173ba32a163>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(original_images, IMG_ROW, IMG_COL, transformation)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         transformed_images[i] = np.expand_dims(cv2.warpAffine(original_images[i], trans_matrix, \n\u001b[0;32m---> 79\u001b[0;31m                                                               (IMG_COL, IMG_ROW)), axis = 2)\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# for debugging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /tmp/build/80754af9/opencv-suite_1535558553474/work/modules/imgproc/src/imgwarp.cpp:2619: error: (-215:Assertion failed) (M0.type() == 5 || M0.type() == 6) && M0.rows == 2 && M0.cols == 3 in function 'warpAffine'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Automating experiments.\n",
    "# 3. evaluate trained models\n",
    "#\n",
    "# ---------------------------\n",
    "acc, confs, confs_misclassified = evaluating()\n",
    "\n",
    "# print reports\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "pd.DataFrame(data = {\n",
    "    'Model': M,\n",
    "    'Test Acc': acc,\n",
    "    'Average Confidence': confs,\n",
    "    'Average Confidence (misclassified)': confs_misclassified\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Automating experiments.\n",
    "# 4. craft and save adversarial examples\n",
    "#\n",
    "# ---------------------------\n",
    "acc, acc_adv, error_rates, confs = evaluating_attacks()\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "pd.DataFrame(data = {\n",
    "    'Model': M,\n",
    "    'Acc (model)': acc,\n",
    "    'Acc (adversarial)': acc_adv,\n",
    "    'Average Confidence': confs,\n",
    "    'Error Rate': error_rates\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
