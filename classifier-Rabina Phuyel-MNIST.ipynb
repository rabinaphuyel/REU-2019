{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# classifier: cats vs. dogs\n",
    "# dataset: https://www.kaggle.com/c/dogs-vs-cats\n",
    "\n",
    "# ---------------------\n",
    "# import required packages\n",
    "# ---------------------\n",
    "# import required packages\n",
    "# ---------------------\n",
    "from __future__ import print_function\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "#loading data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "#normalization\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f310acd9710>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 700 # You may select anything up to 60,000\n",
    "print(y_train[image_index]) # The label is 4\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(221)\n",
    "plt.imshow(x_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(x_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(x_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(x_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialziation\n",
    "IMG_SIZE=28\n",
    "LR=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data reshaping\n",
    "y_train=y_train.reshape((60000,1))\n",
    "x_train=x_train.reshape((60000,28,28, 1))\n",
    "x_test=x_test.reshape((10000,28,28,1))\n",
    "x_train = x_train[30000:, :]\n",
    "y_train = y_train[30000:, :]\n",
    "#x_train = np.expand_dims([x_train], axis = -1)\n",
    "#y_train = np.expand_dims([y_train], axis = -1)\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 28, 28, 1)\n",
      "(30000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#checking the shape\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJztnXe0FEX2xz9XBBMGEEUEFFSMoGLAgArmLGbBhGnRNYd1Dau/3VX3iLrH7KooKmYxY0RUMIsIBkAUEBWeIoigYBat3x8zt6vm8cLM65me6eF+zuFMv67mdb35TtfcunXrXnHOYRiGYTSNJcrdAcMwjDRjg6hhGEYMbBA1DMOIgQ2ihmEYMbBB1DAMIwY2iBqGYcTABlHDMIwYxBpERWQPEflERKaKyPnF6pRRXkzX6sW0LT7S1GB7EWkGTAZ2BWqAMUA/59xHxeuekTSma/Vi2paGJWP83x7AVOfcNAAReRDoA9QriIgs7tuj5jjnVil3JxrBdC2cNOgKBWpruuana5zpfHtgRvBzTfacUT9flLsDeWC6Fk4adAXTtlDy0jWOJSp1nFvkm0tEBgADYtzHSBbTtXppVFvTtXDiDKI1QMfg5w7AV7Uvcs4NAgaBTQ9SgulavTSqrelaOHGm82OALiLSWURaAH2BYcXpllFGTNfqxbQtAU22RJ1zC0XkVGA40Ay4wzk3sWg9M8qC6Vq9mLalockhTk26mU0Pxjrntih3J4qN6Wq6Vil56RrHJ5o6Vl11VQC6desWnVthhRUAGDFiBAA//PBD8h0zDCO12LZPwzCMGCwWlugxxxwDwFVXXQVAmzZtorbPPvsMgHPPPReA4cOHA2aRGoaRH2aJGoZhxCD1luiSS2b+hOWWWw6ADh06ALDrrrtG16y33noAfP/99wCsvPLKUVunTp0AOOGEEwD49ttvARg1alTpOm0YRtVglqhhGEYMbBA1DMOIQeqn8127dgVghx12AGCbbbYBYMstt4yuadu2LeCn/HWx7bbbAn6BSUOfwC82/fbbbwAkGVtrGEZlY5aoYRhGDFJlibZvn8natd9++0XnDj74YMBbni1btmzS715++eUB2HHHHQFYY401orY111wTgLvuuguABQsWNOkeRmlp3rx5dLxw4ULAZg1ppq6Zo+r666+/Jt2dejFL1DAMIwYVu3deQ5fA+z0vvfRSAHbZZZdFrvv5558B/w31yy+/RNcssUTmu0J9o+Hf3KxZszrvH17z008/AdCvXz8Ann766Xz/jNrYHusSsPrqqwOw1157Red0tvLOO+8AcP/99wMwbdq0UnTBdI1J+LyfdtppgNe1devWUdurr74KwCeffALAp59+CsA333xTim7lpatZooZhGDGwQdQwDCMGjU7nReQOYB9gtnOua/Zca+AhoBPwOXCoc25eozfLY3qg0+vNN988OnfccccBcNRRRwGw9NJLR2269/2FF14AYMqUKQBMnjw5uqampgbwi0YnnXRS1LbUUksBfjqx2mqr5fQjZMyYMQAccsgh0bnp06c39ieFVMy0L2ldG0IXENTtArDSSisB0KJFCwDWXXddIHfa98orrwBw1llnAf5zAl5HdeuoS+bee++NrrnpppsA+Pzzz+N0HypIVyietklM53VBVzUE74rRMSBcRPruu+8AWGaZZQC4/vrrAR+GCPD6668Xq3tFm87fBexR69z5wEvOuS7AS9mfjXRxF6ZrtXIXpm1iNBri5Jx7VUQ61TrdB+idPR4CjALOK0aH1Bo57LDDonP7778/4C1QEV9v6/LLLwf8woEuMIXo9R9++CHg99CDD4nSa9TK3GIL/wWk1qpmfwqtZHVo13XfSiZpXRtCF4SOP/746NysWbMAWGWVTMVa1Wnq1KnRNTqj2GijjYDcsDRFw57U4unbt2/U9tprrwEwY0amAOYff/wR90+pCCpJ2/pYdtllAfjb3/4G+Gcc/ELy77//DuQ+W/r/VE9dhOrY0ZeO+vPPPwF48803S9L32jQ1TrStc24mgHNupoisWt+FVj0wVZiu1Ute2pquhVPyYPt8qweqJbjJJpsAuds2W7VqlXPNF1/4ctAa4tBQ8G1tv++dd965yDXqY9FA+jBoX/uk/dh0002jtpdffhlInyUal6ZWhVRfJcDuu+8OeGtknXXWidrmzp0LeEv/uuuuA2D06NHRNTojuOyyyxa5j/o51SeqmbzCcJn+/fsD3up9//33o7ZKCuZOkqSqferzpZqr9Ql+e/UFF1wAwMSJvgxUjx49AD8+bLzxxkBueJtqrrPaIvpI66Spq/OzRKQdQPZ1dvG6ZJQR07V6MW1LRFMt0WFAf2Bg9vXJuB1R35eusHbv3j1qU7+W5vq8/fbbo7axY8cC3g/SVNSSHDlyJJD7zaiWqFq06peBqsuAX3Rda6MREgCnn346ABtuuCHgIysAhg4dmunQsExFX42w0K2/ADvvvDOQ6w9TdIbw0EMPAT7BTBiZccABBwBe1yuvvDJq0yD9KqLk2haCPkM6Mwlni//+978BuPnmm4HcWcFbb70F+OddfaKHHnpodI1uBdf1jSOOOCJqe/7554v4V2Ro1BIVkQeAt4D1RKRGRI4nI8SuIjIF2DX7s5EiTNfqxbRNlnxW5/vV07RzkftiJIjpWr2YtslSMVmctJyxBlnXlcFFA+ife+656FyxMyppWEVdU0QNsdKsTlA9YTGlZv311wfgxBNPjM5tttlmgJ/KXXHFFVGblrDWqdyRRx4J5LoD1OWjC47PPvts1Hb33XcDPiBfN0VsvfXW0TW77bYb4HMxfPnll1GbbuIo0Z7sxR7dzKKusnCjhZY0V13DkMba7jOd8ofuNw15UzfgPffcE7WpC0jDHYuBbfs0DMOIQcVYohrSEloDtdHwlLiLSA2hloduMwzRMKjQElXrNMwaZdSPhq+A11Gt/+233z5qU+tUw8kOP/xwILfctV4zf/58AP773/9GbWEoFPiA+jvuuCM6p4tUqvWee+4ZtT388MOAWaKl4scffwT8dk3VNzyeOXMmADfccEPUpuFo+tlRi1a3ZINfUFLrVu8FvmKF/r9izCTNEjUMw4hBxVii8+ZlciE0ZImutdZaQNOz1+eDWkr6LQjen6fJMMIQp7XXXhvIDQg2FkX92WFAu/o0tYS1+j3BJ5vRxCGqeWg5vP3224DP76rhaXWh1oiGToHfPPF///d/gC+fDdC7d28APvjgA8CqGRSbr7/+GoAJEyYAfjYC3pd5zjnnANC5c+eoTWcUOkPQGeyxxx4bXRP6VyHXEtVQxmKuZZglahiGEQMbRA3DMGJQMdN5NbNrm+ngF5TUzA+nXePGjQP8tC8u6nAOswX17NkT8NN5LZYFPjTLpvMNowsBjz32WHRO3SS6oBMuzukinmbr0QUFDWkBePLJzKYbnXIXii5G6FQyzFWqi1yDBg0CbDpfKjQLm4Y2gn/vNZNanz59ojYdJ3RRURd2w9wVOk7oZ+6qq66K2saPH1/cPwCzRA3DMGJRMZaoohboV199FZ0LM++AX2ACH5Qf1xLVgF7NDqMBu+E99NsvXHTSBTEjP957773o+Oyzzwbg8ccfB3J1nT07kx9DLVJd8AvzJsTNW6AB2nVZmWrhhAseRuk47zyf2lSze2mGposvvjhqq53/V9G8GuAXknRfvVa9gNwQu2JhlqhhGEYMKs4SVQsk9DFqiINahPvss0/Uppl/9NtGLdl8S0HrN5oGXh944IGA35IYXqOWz0cffRS1lagEb9USZuRRv7P6O8PZhPon9VX/X+iPjotamR06dFikTXPWarZ8m3GUBtU33Nyinwd9BkPN1c+pYUy6KSIMb9OM9pprOAxxKgVmiRqGYcSg4izRjz/+GMityqjB7fvuuy/gfSXgc0ButdVWgM9aHwbtz5kzp977aR5TXSE+6KCDAL89DLxVq9bJLbfcErXplkOj6dTlk9Rg6GJnmA8DsTUaoHZVA/CZ8Zu68m94wmRCOqvTjQ6akX7vvfeOrtlggw2Auivv6uxFa6o98cQTQG4uWtU139loXPLJJ9pRREaKyCQRmSgiZ2TPtxaRESIyJfvaqvTdNYqF6VqdmK7Jk890fiFwjnNuA2Br4BQR2RArwZp2TNfqxHRNmHySMs8EtErgAhGZBLSnRCVY1Qms+STBlzhWJ7/mIAS/IDRgQKZAoZaaCPMFqovgkUceAXLDVo4++mjAFy0L9+kqujdbA4M112SaSVrXSiHMAKZ5D9T1E2aICsPY0kS5dNXpOfiigLpRIgwX1MB5XVDSgPowZEkXGPU50xJAAM888wwATz31FOCf5VJmdmuMgnyi2VrW3YHRWAnWqsF0rU5M12TIexAVkZbAo8CZzrn5tYNd66OpJVjDoFjN1qOlT3W7IMBSSy0F+OBozVLeq1ev6Bq1KjS4u0uXLlFb6LTO9hfw2WLAZ0nXLabVlM0+aV3LTVixQDdW6Owj/Ns1z2VaSUpXnQlqcTnwoUn6TIbFBdU61WdILdIXX3wxukYzfd14441ArpUZPpeVQl4hTiLSnIwg9znndPOzlWBNOaZrdWK6JkujlqhkvsIGA5Occ1cHTYmVYNVg28GDBwPwxhtvRG0nn3wy4OuyaDiFJiEA70ttCE1goP6XMAO6fkuWYstYuagEXcvBDjvsEB3rjEStNA3chvRuokhaV00WElYlUMteZ3mh9Vi7dpWGkI0aNSq6Rtcg0kI+0/mewFHAeBHRjLoXkhFjaLYc63TgkNJ00SgRpmt1YromTD6r868D9TlUrARrSjFdqxPTNXkqbsdSQ6jDWUOWwO9j151GPXr0APyCE8Dqq68O1F18TqcX6iLQjELh9EJDrIz0ou4ddfuAn3ZqvoYwV6mRH+oCCRdydVeYPq/hdF6fXXXR6bS+1PvbS4ntnTcMw4hBqixRJcyAroWuNLheM/KE2e9rZ78Os1vb3vfFA108CnMq6CxEN3Y0VOjOqBsNVTr99NOjc5rzU63LalqQrQuzRA3DMGKQSks0pPZ2r5qampxXwwBvDYVbfjXwOyzjbDSN8H1d3HKvmiVqGIYRg9RbooaRD+oXDyMtNAIjDLI3jEIxS9QwDCMGNogahmHEQJJKoQ/pyvZTIsY657YodyeKTVp11VCcuKWXMV2rlbx0NUvUMAwjBkkvLM0Bfsy+po02xO/3msXoSAWSSl2zFqjpWj+p1DVLYromOp0HEJF30zj1SWu/kyKt709a+50UaX1/kuy3TecNwzBiYIOoYRhGDMoxiA4qwz2LQVr7nRRpfX/S2u+kSOv7k1i/E/eJGoZhVBM2nTcMw4iBDaKGYRgxSGwQFZE9ROQTEZkqIucndd9CEZGOIjJSRCaJyEQROSN7vrWIjBCRKdnXVuXua6WQBm1N18IxXfPsQxI+URFpBkwGdgVqgDFAP+fcRyW/eYFka3K3c86NE5HlgbHA/sAxwFzn3MDsB6qVc+68Mna1IkiLtqZrYZiu+ZOUJdoDmOqcm+ac+w14EOiT0L0Lwjk30zk3Lnu8AJgEtCfT3yHZy4aQEcpIibama8GYrnkSaxAtwNxvD8wIfq7JnqtoRKQT0B0YDbR1zs2EjHDAquXrWWkpcBqXOm0XV12hup/Zcuna5EE0a+7fBOwJbAj0E5EN67u8jnMVHVslIi2BR4EznXOLTTW7AnWFlGm7uOoK1f3MllVX51yT/gHbAMODny8ALmjoWjIiLM7/vmnq+53Uv0J0Da4v9/ta7n8Vr2sTn9lyv6/l/peXrnGyONVl7m9V+yIRGQAMALrFuFe18EW5O5AHhepqpENXyENb0zWHvHSN4xPNy9x3zg1ymWwqB8S4l5EcBenqUpjhZzGmUW1N18KJM4jWAB2DnzsAX9V3sXPu2Rj3MpKjIF2NVGHaloA4g+gYoIuIdBaRFkBfYFhxumWUEdO1ejFtS0CTfaLOuYUiciqZBaNmwB3OuYlF65lRFkzX6sW0LQ1WqC5ZrKBZdWK6VidWqM4wDKPU2CBqGIYRAxtEDcMwYmCDqGEYRgxsEDUMIzWICCJ17RkoHzaIGoZhxMAGUcMwjBjESUBiGIZRFJZaaqnoePnllwdgrbXWAmDttdeO2n777TcAll56aYBoaj9hwoTomtmzZwPw1VfJ7Gg1S9QwDCMGi4Uluv766wPQpk0bAKZNmxa1JfVtZRhG/ey6667R8cEHHwzA1ltvDcAKK6wQta200koA/PTTTwAss8wyAHzyySfRNS+++CIAn332GQBvvvlm1PbBBx8Uve9miRqGYcSgavfOX3HFFdHxNttsA8Byyy0HwFNPPRW16fHYsWOT6JbtsW4A9YUBtGqVqXCrn8+5c+cC3gIJ2xpCrRn1qy2xhLcbFi5cCMD48eMBmDx5ctSmvrc8MV2biM4SzznnnOjcCSecUJTfPXXqVCB3tqkaDxw4EIBPP/20oV9he+cNwzBKTaODqIjcISKzRWRCcK61iIwQkSnZ11al7aZRbEzX6sW0TZZGp/MisgPwA3C3c65r9tyVwFzn3MBs2dVWzrnzGr1ZAtODI444AoB777233mtmzpwZHd95550ADBo0CIAvvihpuZyKmfZVkq7t2rUDYP/9fWnwAQMG5LTp9Gvw4MHRNQsWLGj0d19zzTUAHHrooYAPjQH4/fffAZg+fToAZ511VtT2zjvv5FzTCBWjKxRP2ySeV33u9thjj+icumzatm0L5Oqsbh5dSNp8880BH9YEsMoqqwDUubPp119/BWD48OEAXH755QCMGTMmuuaPP/7Qw+JM551zrwJza53uAwzJHg8B9sdIFaZr9WLaJktTQ5zaOudmAjjnZorIqkXsU5NQB3WXLl2A3AWIZZddFoDXXnsNgO+//z5qu/DCCwGYNWsWANdff33pO1u5lFxXDUkBr9XJJ58MwOGHHx61qcWoOmpoS6H7pnUxUX/PKaecErVtueWWAJx00kkAXHfddVHbsGGZqhnXXnstAPPnp75EfUU9swcckKlbedBBBwG5z2v//v0BPwvo1atX1Kafg4kTMwn5v/nmGwA22WST6JqVV14ZgO222w6A3r17R20a1L/TTjsBflaqvwcaXWxahJLHiVoJ1urEdK1OTNfCaeogOktE2mW/0doBs+u70Dk3CBgEpfWxqA90gw02ALz1CTBu3DgAdthhBwD22WefqE1DX9QK6dChAwB///vfS9XVSqbkum677bbR8dVXXw3AOuusA8APP/wQtWnY0eOPPw7AbbfdBhRuETZv3hzwIUujR4+O2vRzsddeewHQrVu3qE19sbfcckuT7luB5KVtUs/r9ttvD8CSS2aGoEsuuSRqU4101qE6gfeTzpkzR/sLwMiRI6NrVLsHHngAgDXXXDNqO/fccwFv3aol3L59++ga9b+/8cYbef0tTQ1xGgb0zx73B55s4u8xKgvTtXoxbUtEo5aoiDwA9AbaiEgN8E9gIDBURI4HpgOHlLKTDXHrrbcCfpWuLnSFVnn77bejY90SphasBmfr6jDAY489Bvhvv2qgXLqedtpp0bG+56+++irgrU7wPsmamhogv8D6ulBLR62a0Pemq75Dhw4F4OKLL47a1JrZeeedAXjkkUeAvFfry0olP7M661Dfpm7B1mcspC7Nde2iIdTPqa8adA/w1ltvAbDjjjsCPipAt4SD33aaryXa6CDqnOtXT9POed3BqEhM1+rFtE0W27FkGIYRg1RmcdJwJvBTwtqEYUy6oPT5558D8Prrr0dtat736dMH8NN5XZAAv99Wzfs0TOkqld122y061vf4jDPOAOCjjz6K2uLmdNB9+Kuvvjrg98yHe+L//PNPAB566CEALrrookXadLoZBGAbBRLmK1D3ik6nNeOShqIBfPvtt0W9f6i5Hj/xxBOAdyHpcw+Fu+3MEjUMw4hBKi3Rjz/+ODoOLUbwAfW//PJLdO4vf/kLAFOmTAFyLVHdRqiWhwb6hqE4Gv507LHHArkhF0ZhhFaGhpOVIpPYLrvsAviAa/1c6La/kO+++w6AFi1aLNKmVol+PozCCd873WChFmnnzp2BunUpJbU/c+Fic6GYJWoYhhGDVFqiYe5B3R6o+UDV/xlu7+vevTsAxx13HOD9oOCtUk1Eor9HfwbYbLPNAHj33XcBOPHEE6M2DQI3Gkb9YhoqBHD66acDPgBak0GAzx9a2z8VbvvUY30Nk1jcdNNNAHz55ZeA39pZl0XZrFkzwFtH4XXquyt0K6BRNzNmzAD850G3aIbB7vmEMVUSZokahmHEwAZRwzCMGKRqOq+hTZtuuml07sknM7vXHnzwwZxrX3rppej4sMMOA/x+XS0XArmLTAAffvghkLsDSnMe6gKV/hxep9NFo250yv3KK69E53RniL7qbhaA999/H4Arr7wS8PvqwxIimvfgqKOOAmDfffeN2mrvyQ6LE9ZGw1508Ql8yEu4k8VYlBVXXBHwbjTILb9TG90JpjpquGCYDzRtmCVqGIYRg1RZoprNOrQkdS90mK0ecsOgwsB78KFK4BeZalukIbqPXhedNLMP+EUmXXzSa0PLpwoyAMVGg9Wfe+656Jxmy9EwJA15Aj972GijjQAfAqNZfMBnXVIrVUPYwOdUuOeee4CGQ5TUEtVs9uBzjVqQfcN07doVyM0FqxmSbr/9diD3WdSicfPmzQOgZcuWAOy+++7RNapZgcUCy4ZZooZhGDFIlSXasWNHAH788cfonG7rU2tTfVjnnefLx2jGGCXcKlrbgm0ItW7C8srqH1XLRdvuu+++6BoN7NVA/sWZMKhaw5BuvvlmANZaa62o7ZBDMkmGNGheLZZwE4W+xzozCOvkKPlYkmrxPPzww9E5nWFoWWUjF/VxazhSuG1TfdM6S9SwJvDPp1Y40EzznTp1iq6pnQO20jFL1DAMIwb5VPvsCNwNrAb8CQxyzl0nIq2Bh4BOwOfAoc65eY38rlj7+/QbqmfPntE5zUquVozmiOzXz2cD0287XX1VnwvED5bXb2S1SDWCIMymrSuYK664YsVUhawkXSsFnekADBmSqen2wgsvAN5/Ww+Lra5qgYar81q3TCMcvv7666itdevWgN9iq1EU4SYMrbqquWTLSHGqfQILgXOccxsAWwOniMiGwPnAS865LsBL2Z+N9GC6Viema8LkUzJ5pnNuXPZ4ATAJaI+VYE01pmt1YromT0ELSyLSCegOjKYMJVg1MHfChAnRuXXXXRfwDmt1UIflb9977z3AlwKZPn160fqk7hANxNfSrTptgdwFk0qk3LpWCprNCfx0Xj9faSQJXXWRV/OCgn8G9VkIQ9fqQ0PZIHfxMA3kPYiKSEvgUeBM59z8fOt/WwnWysZ0rU5M1+RodGEJQESaA08Dw51zV2fPfQL0DkqwjnLOrdfI7ynZAsQKK6yg9wAWDbBPmjDPaZAJv2IWICAduiZJmIFdFwN1RtFIFifTNUAXmzQAX7N0gc8nWptRo0ZFx5qlrQLy9hZnYUkyo9JgYJIKksVKsKYY07U6MV2TJ5/pfE/gKGC8iLyfPXchFVKCVam0rZUpqMOUCl2TJNwaqtsS9TVFlF1X9ZOOGDECyN2mrQlIdKam1n8YrF/MNYskyKdk8utAfQ4VK8GaUkzX6sR0TR7bsWQYhhGDVO2dNwwjPWiJci3LAzB8+HDA53nVvKJauhh8Vq60YJaoYRhGDPIKcSrazaokFCYGFRUKUyxMV9O1ULQ4oIZBPfroo1GbBttXQJnqou2dNwzDMOrBfKKGYSSO5nkNM6qlFbNEDcMwYmCDqGEYRgxsEDUMw4iBDaKGYRgxsEHUMAwjBjaIGoZhxCDpEKc5wI/Z17TRhvj9XrPxS1KJ6VqdmK55kOiOJQAReTeNuzvS2u+kSOv7k9Z+J0Va358k+23TecMwjBjYIGoYhhGDcgyig8pwz2KQ1n4nRVrfn7T2OynS+v4k1u/EfaKGYRjVhE3nDcMwYpDYICoie4jIJyIyVUTOT+q+hSIiHUVkpIhMEpGJInJG9nxrERkhIlOyr63K3ddKIQ3amq6FY7rm2YckpvMi0gyYDOwK1ABjgH7OuY9KfvMCydbkbuecGyciywNjgf2BY4C5zrmB2Q9UK+fceWXsakWQFm1N18IwXfMnKUu0BzDVOTfNOfcb8CDQJ6F7F4RzbqZzblz2eAEwCWhPpr9DspcNISOUkRJtTdeCMV3zJNYgWoC53x6YEfxckz1X0YhIJ6A7MBpo65ybCRnhgFXL17PSUuA0LnXaLq66QnU/s+XStcmDaNbcvwnYE9gQ6CciG9Z3eR3nKjosQERaAo8CZzrn5pe7P0lRoK6QMm0XV12hup/ZcuoaxxItxNyvAToGP3cAvopx75IiIs3JCHKfc+6x7OlZWf+L+mFml6t/JabQaVxqtF3MdYUqfWbLrWuTF5ZE5GBgD+fcCdmfjwK2cs6dWse1S5JxUneO0ddqYI5zbpVyd6IhCtE1274k8HuCXaxEKl5XaNIza7rmoWscSzQvc19EBgBvA3/EuFe18EW5O5AHeesqIu+S0XZxJw26Qh7amq455KVrnEE0L3PfOTfIObeFc65LjHsZyVGorqnL8LMY06i2pmvhxBlExwBdRKSziLQA+gLDitMto4yYrtWLaVsCmpyU2Tm3UEROBYYDzYA7nHMTi9YzoyyYrtWLaVsaEk1AIiIVGyKREGOrcZpkupquVUpeuloCEsMwjBgkXWMpMZo1axYdr7pqZrPC779nIjbmzEljyRjDMCoRs0QNwzBiUHWWqEgmFK5Dhw7RucsuuwyA7bbbDoDrr78+arvmmmsS7J1hGMVAn/OVVlppkbZ58+Yl2hezRA3DMGJQdZao+kLXWWed6NzBBx8MwK+//grAH3/Y5inDqHT0WQ6f1+bNmwOwyiqZ3ZjnnnsuAL169Yquef755wH45z//Cfi1kFJhlqhhGEYMbBA1DMOIQdVN5xcuXAjAt99+G52bNWsWAG3btgWgZ8+eUVu4yGSkE11E3GmnnaJzOoV7+umnAfjxxx8B+PPPPxPundFU9HndaKONonOq9fbbbw/A0UcfDeSGNHbt2hWABQsWAHDjjTdGbXqumJglahiGEYNm227gAAANWElEQVSqs0QVdTyD/5ZSK9WC7dODbpRYY401AJg6dWrU9v333wMwaNAgAHbeeeeobcaMTGWLvn37AvC///0v5zzAd999B8Ds2Zl8vfr5MJJHQ5YA1l57bcBbmUceeWTUps/1UkstBfjPQOvWraNrdPFp9913B+Cpp56K2iZMmFD0vpslahiGEYOqtUTbtGkTHes3U13+UqP8rLXWWgBssYXP9aDH6g9TS+XWW2+NrhkzZgzgLUrVOfyd7dtnaqt17JhJozl58uToGvWPvf766wDcd999UZtZpcmw7LLLArD66qtH58466ywADjzwQABWW221qE0tzwcffBCAFi1aALn+cLVWN9wwUz4qDMivK2wqLmaJGoZhxKDRQVRE7hCR2SIyITjXWkRGiMiU7Gur0nbTKDama/Vi2iZLPtP5u4AbgbuDc+cDLznnBmZrV58PnFf87jWdlVdeOTpWE37+/Ewl1S++SEtJnJJyF2XWdcUVVwTg0EMPBeCggw6K2nQ6vsIKKwAwZcoUwE//AObOnQvA8OHDF/n/OrXXBYhNNtkEgO7du0fX6A62zTffHPDhUJB6l89dpOSZ1Sm37i4Cn+NCtf/888+jtnvvvReA//znP4BfTOzRo0d0jU7nP/vsMyA3/KkUuxUbtUSdc68Cc2ud7gMMyR4PAfYvcr+MEmO6Vi+mbbI0dWGprXNuJoBzbqaIrFrEPhWF0GJRdLFAFyKMRSi5ruGC37HHHgvACSecAPhwJvBaffrpp4Bf9Hnttdeia3755RcAXnjhBSA3e49aIz/88AMAb731FgC77LJLdI0uSqh12rmzr+itCxhVtMBUUc9s7969AT972GeffRa55vHHHwf8TAPglVdeAbz2upHm559/jq7RDRW6GFnqmWfJV+ezJZMHlPo+RrKYrtWJ6Vo4TR1EZ4lIu+w3Wjtgdn0XOucGAYMg2ZotGkAN3qrQQG21boxFKJmuSy+9NAB77LFHdE7zvH71VaZq78UXXxy1vf12puz56NGjG+30zJkzAZg+fXp0Ti1RDV8aOXIkkGsJb7zxxgAsuWTmMdh3332jtq+//hqAmpqaRu+fEvLSNqnn9fTTTwdyQ5MU9U1rOFtoidZGPzvqHwfv99SZiX72SkVTQ5yGAf2zx/2BJ4vTHaPMmK7Vi2lbIhq1REXkAaA30EZEaoB/AgOBoSJyPDAdOKSUnWwKoS9LV2rbtWu3SNviStK6qg9LrT+A3377DfBB848++mjU1hQLcOzYsdGxBuur33PSpEkA3HPPPdE1F1xwAeB9sXvttVfUptsDH3744YL7UW4q7ZnVVXaAQw7J3FajJTR64uOPP46u0fdcZyMNoQlJ1lxzzeiczizCAP5S0ugg6pzrV0/TzvWcN1KA6Vq9mLbJYjuWDMMwYlC1e+d1mgDQsmVLwAdXH3fccVGbLkBo2JOGQ4TTPl2kci6xdbGqZfnll4+ONQxtmWWWAXKLCzZlOv/qq69GxyeeeCLg98zrlPLFF1+Mrtlzzz0B2G233YDckjIa8J3G6XyloJsptt122+jcRRddBHjXmj5bl1xySXTN0KFDgfwC4zW3gj7b4EObdAFZw9xKhVmihmEYMahaSzS0ZHRRQy2NU089NWrTxQj91lSrNbRkNft9KbJiL2588MEH0fESS2S+w7t06QLAVlttFbXls6hQmzfeeGORc2qJaqjUtGnTorZrr70W8OExYcC35rB87LHHAHjnnXeA3KBuo2E22GADAP76179G59QCVctRN0E88MADBf3u9ddfH4Bu3boBubMIrWqgwfpmiRqGYVQwVWuJjho1Kjq+9NJLc17DhAYacrH11lsD3gd2/PHHR9do7kKzROMT6qI+Zk02ots/wVsoagHmQ7jV98svv8w5p/7WcAug9kVnLaFf7YADDgC8/1wDtz/88MO8+7O4omFlOgvQDPPgww1VH604kC86e9FM9mFYmqKJR/Repd7mbZaoYRhGDGwQNQzDiEHVTufDwle6G0KniGGZZN17G07xIXdq2KqV5a8tFuHOlJtvvhmAww8/HPC5JcHvo//Xv/4FwPjx4wG/yylEw5fOOOOM6JwuFOpClu5SC8Nm9Fh3Mw0bNixq0/yU+qpZh8JCZ1Z+uW5UI82YpeWqQ7R4nGZlyhfdhbTjjjvm/Kz5EwDuuusuIHcHXCkxS9QwDCMGVWeJ6r7Zrl27Rud0kUjDVTSjD/is1+qo1ozm4QJEmKfSKB66oUHLIYclj9Xy+8c//gHA4MGDgdzQtXXXXReAvffeG4D+/ftHbarZyy+/DMDEiRPr7YdapGGw/u233w54S1g/Q08+6fN2WIWEulErURdrw0JxGk52//33A36hqC6rXjdhaKgUwG233Qb4UCkNRbzhhhuiazRcKqnn1ixRwzCMGFSdJaoZecI8herfVH9W6BfTMAzdAqj+nDDYO/S3GMXjvffeA3zeyDCzvWZh0hCWbbbZBoB33303ukb9YWrJhtaMhtBoyJrmlG2IsK6Sbj3cbLPNcvoR1vLRLYsWgJ+LhoppqFO4PqGWp4aOqWa6NhH+v169egHQt2/fqE1nH7opRj8P6mOFRdc3So1ZooZhGDHIJ59oRzJVA1cD/gQGOeeuE5HWwENAJ+Bz4FDnXNmch+oLVcshzGB+4403Av5bS4NwwdfVUR/qN998A8Cbb74ZXfPTTz+VqttloxJ0VYtFfZG6Wg9wxBFHAN5PutpqqwF+xgDeqtHfE1qS6nNrqt9SLaMrrrgC8P457RfAnDlzgFwfe7mpBF1Vh7p8khrpon7snj17AjBjxozoGn0+11tvPSA3MY1u0NCZhfrVk7Y+Q/KxRBcC5zjnNgC2Bk4RkQ3xJVi7AC9lfzbSg+lanZiuCZNPyeSZzrlx2eMFwCSgPVaCNdWYrtWJ6Zo8BS0siUgnoDswmgorwaphFLqgFJYk0KmZOqx1yg8wYMCAnHNPPPEEkFtqotopt67z588HfJA0+D3q++23HwB9+vQBcjPy6OKRbqJ46KGHojYtNNdUdNo4ZcoUwC9cnH322dE1ujmgkqbzIeXSVcPQ1D0T5pBVt5lO0fU1DElUVIMwZ8Xzzz8PwEsvvQTAM888A8TXOw55D6Ii0hJ4FDjTOTc/XHFr5P9ZCdYKxnStTkzX5MhrEBWR5mQEuc8591j2dEWVYNWyqBqypDkFwWevV6smzGyvCwZ33nknAPfeey+QW363WqlkXceNGwf4haGBAwcCsNxyy0XX6CKFLjLoQk8x0ZA3tXyOPvroqE2zqlca5dZVt3k+++yzgA9LAlh77bUBvxCkC7uhJdm2bVvAbxEOqxFcffXVgF+0Cp/zctGoT1QyX2GDgUnOuauDJivBmmJM1+rEdE0eaaxukIhsB7wGjCcTMgFwIRk/y1BgDbIlWJ1zcxv5XSWzRNVC0W1hYZ5Bncqo1RkGz1911VWA94Wq/7REySXGOue2KMUvLpS06FpphFnaTz75ZAC6detmuuaJrj3omoVuVAjLG2tIofq/1S8NfoNDQuSlaz4lk18H6nOoWAnWlGK6Viema/LYjiXDMIwYVM3eeXVma7YedViD31utYTOXXXZZ1KYFzHRxwsoiGw0xYsSI6Dhc5DLyQxcMG6KhzE6ViFmihmEYMWh0YamoN6uQBQjNIQq5GZ0SoGIWIIpJpeiaBLphA7wlOm/ePNO1OslLV7NEDcMwYlA1PtFCSNj6NKqIsMZTXfWejMUPs0QNwzBiYIOoYRhGDGwQNQzDiIENooZhGDGwQdQwDCMGNogahmHEIOkQpznAj9nXtNGG+P1esxgdqUBM1+rEdM2DRHcsAYjIu2nc3ZHWfidFWt+ftPY7KdL6/iTZb5vOG4ZhxMAGUcMwjBiUYxAdVIZ7FoO09jsp0vr+pLXfSZHW9yexfifuEzUMw6gmbDpvGIYRg8QGURHZQ0Q+EZGpInJ+UvctFBHpKCIjRWSSiEwUkTOy51uLyAgRmZJ9bVXuvlYKadDWdC0c0zXPPiQxnReRZsBkYFegBhgD9HPOfVTymxdItiZ3O+fcOBFZHhgL7A8cA8x1zg3MfqBaOefOK2NXK4K0aGu6Fobpmj9JWaI9gKnOuWnOud+AB4E+Cd27IJxzM51z47LHC4BJQHsy/R2SvWwIGaGMlGhruhaM6ZonSQ2i7YEZwc812XMVjYh0ArqTqdnd1jk3EzLCAauWr2cVReq0NV3zwnTNk6QG0brqYFd0WICItAQeBc50zs0vd38qmFRpa7rmjemaJ0kNojVAx+DnDsBXCd27YESkORlB7nPOPZY9PSvrf1E/zOxy9a/CSI22pmtBmK55ktQgOgboIiKdRaQF0BcYltC9C0JEBBgMTHLOXR00DQP6Z4/7A08m3bcKJRXamq4FY7rm24ekgu1FZC/gWqAZcIdz7j+J3LhARGQ74DVgPPBn9vSFZPwsQ4E1gOnAIc65uWXpZIWRBm1N18IxXfPsg+1YMgzDaDq2Y8kwDCMGNogahmHEwAZRwzCMGNggahiGEQMbRA3DMGJgg6hhGEYMbBA1DMOIgQ2ihmEYMfh/NRzKs9bXK9oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define data preparation\n",
    "datagen = ImageDataGenerator(rotation_range = 270)\n",
    "# fit parameters from data\n",
    "datagen.fit(x_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
    "    # create a grid of 3x3 image\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(X_batch[i].reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# define data preparation\\ndatagen = ImageDataGenerator(zca_whitening=True)\\n# fit parameters from data\\ndatagen.fit(x_test)\\n# configure batch size and retrieve one batch of images\\nfor X_batch, y_batch in datagen.flow(x_test, y_test, batch_size=9):\\n    # create a grid of 3x3 images\\n    for i in range(0, 9):\\n        plt.subplot(330 + 1 + i)\\n        plt.imshow(X_batch[i].reshape(28, 28), cmap=plt.get_cmap('gray'))\\n    # show the plot\\n    plt.show()\\n    break\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# define data preparation\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "# fit parameters from data\n",
    "datagen.fit(x_test)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(x_test, y_test, batch_size=9):\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(X_batch[i].reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"datagen = ImageDataGenerator(samplewise_std_normalization = True)\\n# fit parameters from data\\ndatagen.fit(x_train)\\n\\n# configure batch size and retrieve one batch of images\\nfor X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\\n    #create a grid of 3x3 images\\n    for i in range(0, 9):\\n        plt.subplot(330 + 1 + i)\\n        plt.imshow(X_batch[i].reshape(28, 28), cmap=plt.get_cmap('gray'))\\n        # show the plot\\n        plt.show()\\n        break\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''datagen = ImageDataGenerator(samplewise_std_normalization = True)\n",
    "# fit parameters from data\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
    "    #create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(X_batch[i].reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
    "        # show the plot\n",
    "        plt.show()\n",
    "        break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"datagen = ImageDataGenerator(samplewise_std_normalization = True)\\n# fit parameters from data\\ndatagen.fit(x_test)\\n\\n# configure batch size and retrieve one batch of images\\nfor X_batch, y_batch in datagen.flow(x_test, y_test, batch_size=9):\\n    #create a grid of 3x3 images\\n    for i in range(0, 9):\\n        plt.subplot(330 + 1 + i)\\n        plt.imshow(X_batch[i].reshape(28, 28), cmap=plt.get_cmap('gray'))\\n        # show the plot\\n        plt.show()\\n        break\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''datagen = ImageDataGenerator(samplewise_std_normalization = True)\n",
    "# fit parameters from data\n",
    "datagen.fit(x_test)\n",
    "\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(x_test, y_test, batch_size=9):\n",
    "    #create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(X_batch[i].reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
    "        # show the plot\n",
    "        plt.show()\n",
    "        break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0701 10:07:24.657207 139850247288576 deprecation_wrapper.py:119] From build/bdist.linux-x86_64/egg/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "W0701 10:07:24.657457 139850247288576 deprecation_wrapper.py:119] From build/bdist.linux-x86_64/egg/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "W0701 10:07:24.661727 139850247288576 deprecation_wrapper.py:119] From build/bdist.linux-x86_64/egg/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0701 10:07:24.664706 139850247288576 deprecation_wrapper.py:119] From build/bdist.linux-x86_64/egg/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "W0701 10:07:24.671698 139850247288576 deprecation_wrapper.py:119] From build/bdist.linux-x86_64/egg/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W0701 10:07:24.672046 139850247288576 deprecation_wrapper.py:119] From build/bdist.linux-x86_64/egg/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# construct the cnn model for this project\n",
    "# ---------------------\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected, flatten\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "def conv_net():\n",
    "    convnet = input_data(shape = [None, IMG_SIZE, IMG_SIZE, 1],\n",
    "                        name = 'input')\n",
    "    print(convnet)\n",
    "    # conv_2d(incoming, nb_filter, filter_size, ..., activation)\n",
    "    convnet = conv_2d(convnet, 32, (3,3), activation = 'relu')\n",
    "    # max_pool_2d(incoming, kernel_size, ...)\n",
    "    convnet = max_pool_2d(convnet, 2)\n",
    "    \n",
    "\n",
    "    #flatten the layer\n",
    "    print(\"break_1\")\n",
    "    flatten = tflearn.flatten(convnet)\n",
    "    # fully_connected(incoming, n_units, activation, ...)\n",
    "    convnet = fully_connected(flatten, 5, activation = 'relu')\n",
    "    # dropout(incoming, keep_prob is drop_prob + keep+prob)\n",
    "\n",
    "    #standard recommendation for the Net arch    \n",
    "    logits = fully_connected(convnet, 10, activation = 'softmax')\n",
    "    #convnet = dropout(convnet, 0.8)\n",
    "    \n",
    "    #logits\n",
    "    #logits = tf.layers.dense(inputs=convnet, units=10)\n",
    "    \n",
    "    #regression(incoming, optimizer, learning_rate, loss, name, ...)\n",
    "    convnet = regression(logits, optimizer = 'adam', learning_rate = LR,\n",
    "                             loss = 'categorical_crossentropy', name = 'targets')\n",
    "\n",
    "    return convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0701 10:07:24.690263 139850247288576 deprecation_wrapper.py:119] From build/bdist.linux-x86_64/egg/tflearn/layers/core.py:81: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0701 10:07:24.694643 139850247288576 deprecation.py:506] From build/bdist.linux-x86_64/egg/tflearn/initializations.py:119: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0701 10:07:24.696115 139850247288576 deprecation.py:323] From /home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py:507: __init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "W0701 10:07:24.719639 139850247288576 deprecation_wrapper.py:119] From build/bdist.linux-x86_64/egg/tflearn/layers/conv.py:552: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0701 10:07:24.843682 139850247288576 deprecation.py:506] From build/bdist.linux-x86_64/egg/tflearn/initializations.py:174: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0701 10:07:24.880136 139850247288576 deprecation_wrapper.py:119] From build/bdist.linux-x86_64/egg/tflearn/optimizers.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0701 10:07:24.888078 139850247288576 deprecation.py:506] From build/bdist.linux-x86_64/egg/tflearn/objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input/X:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "break_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0701 10:07:24.975512 139850247288576 deprecation_wrapper.py:119] From build/bdist.linux-x86_64/egg/tflearn/summaries.py:46: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W0701 10:07:25.008608 139850247288576 deprecation.py:323] From /home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0701 10:07:25.114763 139850247288576 deprecation_wrapper.py:119] From build/bdist.linux-x86_64/egg/tflearn/helpers/trainer.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------\n",
    "# define the model\n",
    "# ---------------------\n",
    "convnet = conv_net()\n",
    "model = tflearn.DNN(convnet, tensorboard_dir = 'log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4689  | total loss: \u001b[1m\u001b[32m0.32909\u001b[0m\u001b[0m | time: 12.923s\n",
      "| Adam | epoch: 010 | loss: 0.32909 -- iter: 29952/30000\n",
      "Training Step: 4690  | total loss: \u001b[1m\u001b[32m0.32622\u001b[0m\u001b[0m | time: 12.941s\n",
      "| Adam | epoch: 010 | loss: 0.32622 -- iter: 30000/30000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(x_train,y_train,n_epoch=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.59060404e-09, 2.58607713e-09, 8.05924609e-02, ...,\n",
       "        3.66759814e-05, 5.80159761e-02, 1.26486464e-06],\n",
       "       [7.25683106e-25, 5.64419152e-03, 3.08363742e-05, ...,\n",
       "        9.94089007e-01, 9.87363601e-05, 1.35749302e-04],\n",
       "       [2.68643383e-08, 2.97871808e-13, 5.12922835e-03, ...,\n",
       "        4.00279987e-07, 5.29284999e-02, 2.36205508e-07],\n",
       "       ...,\n",
       "       [9.12116593e-05, 3.20613572e-18, 4.36680416e-08, ...,\n",
       "        1.27822142e-09, 1.28805954e-02, 3.24226785e-05],\n",
       "       [2.80907669e-04, 1.16880428e-09, 1.55519685e-02, ...,\n",
       "        6.46659570e-09, 3.35637815e-05, 8.32762609e-11],\n",
       "       [1.05297939e-08, 6.96988084e-12, 8.01281203e-06, ...,\n",
       "        1.35614740e-04, 7.30844080e-01, 6.49263486e-02]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=model.predict(x_train)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=np.argmax(p,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_y_label=np.argmax(y_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_correct_count=0\n",
    "for i in range(len(prediction)):\n",
    "    if (prediction[i]==real_y_label[i]):\n",
    "        train_correct_count=train_correct_count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Accuracy: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"train Accuracy: \"+str(train_correct_count/x_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Accuracy: 0.9018\n"
     ]
    }
   ],
   "source": [
    "test_correct_count=0;\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "y_test=y_test.reshape((10000,1))\n",
    "x_test=x_test.reshape((10000,28,28,1))\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "p_test=model.predict(x_test);\n",
    "prediction_test=np.argmax(p_test,axis=1)\n",
    "for i in range(len(prediction_test)):\n",
    "    if (prediction_test[i]==y_test[i]):\n",
    "        test_correct_count=test_correct_count+1;\n",
    "print(\"test Accuracy: \"+str(1.0 * test_correct_count/x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7],\n",
       "       [2],\n",
       "       [1],\n",
       "       ...,\n",
       "       [4],\n",
       "       [5],\n",
       "       [6]], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "# Get current session (assuming tf backend)\n",
    "sess = K.get_session()\n",
    "# Initialize adversarial example with input image\n",
    "x_adv = x_test\n",
    "# Added noise\n",
    "x_noise = np.zeros_like(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "epochs = 10\n",
    "epsilon = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "target_class = 10 \n",
    "prev_probs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 11 and 10 for 'mul_6' (op: 'Mul') with input shapes: [11], [?,10].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d4c187f40bf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Perturb the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mx_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_adv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Get the new image and predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m   \u001b[0;31m# Propagate func.__doc__ to the wrappers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1178\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Case: Dense * Sparse.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6488\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6489\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 6490\u001b[0;31m         \"Mul\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   6491\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6492\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/util/deprecation.pyc\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3614\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3615\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3616\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3617\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3618\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2025\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   2026\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 2027\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 11 and 10 for 'mul_6' (op: 'Mul') with input shapes: [11], [?,10]."
     ]
    }
   ],
   "source": [
    "for i in range(epochs): \n",
    "    # One hot encode the target class\n",
    "    target = K.one_hot(target_class, 10)\n",
    "    \n",
    "    # Get the loss and gradient of the loss wrt the inputs\n",
    "    loss = -1*K.categorical_crossentropy(target, convnet)\n",
    "    grads = K.gradients(loss, convnet)\n",
    "\n",
    "    # Get the sign of the gradient\n",
    "    delta = K.sign(grads[0])\n",
    "    x_noise = x_noise + delta\n",
    "\n",
    "    # Perturb the image\n",
    "    x_adv = x_adv + epsilon*delta\n",
    "\n",
    "    # Get the new image and predictions\n",
    "    x_adv = sess.run(x_adv, feed_dict={convnet:x_test})\n",
    "    preds = model.predict(x_adv)\n",
    "\n",
    "    # Store the probability of the target class\n",
    "    prev_probs.append(preds[0][target_class])\n",
    "\n",
    "    if i%20==0:\n",
    "        print(i, preds[0][target_class], MNIST.decode_predictions(preds, top=10)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from keras.models import load_model\n",
    "\n",
    "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del model'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend\n",
    "from keras.datasets import mnist\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.attacks import BasicIterativeMethod\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "backend.set_learning_phase(False)\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "load_data = mnist.load_data()\n",
    "y_test=y_test.reshape((10000,1))\n",
    "x_test=x_test.reshape((10000,28,28,1))\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "sess =  backend.get_session()\n",
    "wrap = KerasModelWrapper(load_data)\n",
    "fgsm = FastGradientMethod(wrap, sess=sess)\n",
    "fgsm_params = {'eps': 0.3,\n",
    "               'clip_min': 0.,\n",
    "               'clip_max': 1.}\n",
    "adv_x = fgsm.generate_np(x_test.shape[0], **fgsm_params)\n",
    "\n",
    "adv_pred = np.argmax(keras_model.predict(adv_x), axis = 1)\n",
    "adv_acc =  np.mean(np.equal(adv_pred, y_test))\n",
    "\n",
    "print(\"The adversarial validation accuracy is: {}\".format(adv_acc))''''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Define a function that stitches the 28 * 28 numpy arrays\n",
    "# together into a collage.\n",
    "def stitch_images(images, y_img_count, x_img_count, margin = 2):\n",
    "    \n",
    "    # Dimensions of the images\n",
    "    img_width = images[0].shape[0]\n",
    "    img_height = images[0].shape[1]\n",
    "    \n",
    "    width = y_img_count * img_width + (y_img_count - 1) * margin\n",
    "    height = x_img_count * img_height + (x_img_count - 1) * margin\n",
    "    stitched_images = np.zeros((width, height, 3))\n",
    "\n",
    "    # Fill the picture with our saved filters\n",
    "    for i in range(y_img_count):\n",
    "        for j in range(x_img_count):\n",
    "            img = images[i * x_img_count + j]\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.dstack([img] * 3)\n",
    "            stitched_images[(img_width + margin) * i: (img_width + margin) * i + img_width,\n",
    "                            (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n",
    "\n",
    "    return stitched_images\n",
    "\n",
    "x_sample = x_test[0].reshape(28, 28)\n",
    "adv_x_sample = adv_x[0].reshape(28, 28)\n",
    "\n",
    "adv_comparison = stitch_images([x_sample, adv_x_sample], 1, 2)\n",
    "\n",
    "plt.imshow(adv_comparison)\n",
    "plt.show()'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
