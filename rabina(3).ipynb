{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "classifier and attacker\n",
    "dataset: mnist\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\" \n",
    "# ---------------------\n",
    "# import required packages\n",
    "# ---------------------\n",
    "from __future__ import division, absolute_import, print_function\n",
    "\n",
    "import cv2\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as tf_K\n",
    "#import time\n",
    "\n",
    "from cleverhans.evaluation import batch_eval\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "tf.enable_eager_execution()\n",
    "tf.set_random_seed(1000)\n",
    "\n",
    "%matplotlib inline\n",
    "#%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 types of transformations.\n",
      "['clean', 'rotate90', 'rotate180', 'rotate270', 'shift_left', 'shift_right', 'shift_up', 'shift_down', 'shift_top_left', 'shift_top_right', 'shift_bottom_right', 'shift_bottom_left', 'horizontal_flip', 'vertical_flip', 'both_flip', 'affine_vertical_compress', 'affine_vertical_stretch', 'affine_horizontal_compress', 'affine_horizontal_stretch', 'affine_both_compress', 'affine_both_stretch', 'erosion', 'dilation', 'opening', 'closing', 'gradient', 'thresh_bin', 'thresh_mean', 'thresh_gaussian', 'samplewise_std_norm', 'feature_std_norm', 'zca_whitening', 'pca_whitening', 'scaling', 'upsampling', 'downsampling', 'horizontal_shear', 'vertical_shear', 'range_shear']\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------\n",
    "# Configuration for the experiment\n",
    "# ------------------------------------\n",
    "# debugging flag\n",
    "debug = True\n",
    "\n",
    "# parameters (model)\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# parameters (dataset)\n",
    "IMG_ROW = 28\n",
    "IMG_COL = 28\n",
    "VAL_RATE = 0.2\n",
    "\n",
    "# parameters (fgsm)\n",
    "eps = 0.25\n",
    "\n",
    "\"\"\"\n",
    "Datasets used to train the models,\n",
    "Each item stands for one type of transformation being applied on the dataset.\n",
    "Specifically, 'clean' means the original dataset, no transformation being applied,\n",
    "and each the rest stands for the transformation being applied on the clean dataset.\n",
    "e.g., 'rotate90' means that each image was rotated 90 deg.\n",
    "\"\"\"\n",
    "# -----------------------------------\n",
    "# Your task:\n",
    "# Please complete this array, adding the transformations of interest.\n",
    "# Please note that the transformations being added here\n",
    "# should be the same you added in the transform function.\n",
    "# -----------------------------------\n",
    "M_ROTATE = ['rotate90', 'rotate180', 'rotate270']\n",
    "M_SHIFT = ['shift_left', 'shift_right', 'shift_up', 'shift_down',\n",
    "          'shift_top_left', 'shift_top_right', 'shift_bottom_right', 'shift_bottom_left']\n",
    "M_FLIP = ['horizontal_flip', 'vertical_flip', 'both_flip']\n",
    "M_AFFINE_TRANS = ['affine_vertical_compress', 'affine_vertical_stretch', \n",
    "                  'affine_horizontal_compress', 'affine_horizontal_stretch',\n",
    "                  'affine_both_compress', 'affine_both_stretch']\n",
    "M_MORPH_TRANS = ['erosion', 'dilation', 'opening', 'closing', 'gradient']\n",
    "M_THRESH = ['thresh_bin', 'thresh_mean', 'thresh_gaussian'] # n\n",
    "M_IMG_AUGMNT = ['samplewise_std_norm', 'feature_std_norm', 'zca_whitening', 'pca_whitening']\n",
    "M_SCALE = ['scaling', 'upsampling', 'downsampling']\n",
    "M_MISC = ['zca_eps_1e6', 'zca_eps_1e8', 'wavelet_trans']\n",
    "M_SHEAR = ['horizontal_shear', 'vertical_shear', 'range_shear']\n",
    "M = ['clean']\n",
    "\n",
    "M.extend(M_ROTATE) # y\n",
    "M.extend(M_SHIFT) # y\n",
    "M.extend(M_FLIP) # y\n",
    "M.extend(M_AFFINE_TRANS) # y\n",
    "M.extend(M_MORPH_TRANS) # y\n",
    "M.extend(M_THRESH) # n\n",
    "M.extend(M_IMG_AUGMNT) # ing\n",
    "M.extend(M_SCALE)\n",
    "M.extend(M_SHEAR)\n",
    "# M.extend(M_MISC)\n",
    "\n",
    "# a walkaround for error of not able to save trained model:\n",
    "# training models one by one\n",
    "# M = ['samplewise_std_norm']\n",
    "print('{} types of transformations.'.format(len(M)))\n",
    "print(M)\n",
    "# -----------------------------------\n",
    "# Your task ends\n",
    "# -----------------------------------\n",
    "\n",
    "\"\"\"\n",
    "Adversarial examples generation algorithms.\n",
    "\"\"\"\n",
    "attacks = ['fgsm'] #, 'jsma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load data\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "def load_mnist():\n",
    "    \"\"\"\n",
    "    Load and process training set and test set\n",
    "    \"\"\"\n",
    "    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "    X_train = X_train.reshape(-1, IMG_ROW, IMG_COL, 1)\n",
    "    X_test = X_test.reshape(-1, IMG_ROW, IMG_COL, 1)\n",
    "    # cast pixels to floats, normalize to [0, 1] range\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "\n",
    "    # one-hot-encode the labels\n",
    "    Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "    Y_test = np_utils.to_categorical(Y_test, 10)\n",
    "    \n",
    "    print(\"Dataset(MNIST) summary:\")\n",
    "    print(\"Train set: {}, {}\".format(X_train.shape, Y_train.shape))\n",
    "    print(\"Test set: {}, {}\".format(X_test.shape, Y_test.shape))\n",
    "    \n",
    "    return (X_train, Y_train), (X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define model structures for some datasets.\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "def cnn():\n",
    "    \"\"\"\n",
    "    Returns the appropriate Keras model.\n",
    "    :return: The model; a Keras 'Sequential' instance.\n",
    "    \"\"\"\n",
    "    # MNIST model\n",
    "    struct = [\n",
    "        layers.Conv2D(32, (3, 3), input_shape=(IMG_ROW, IMG_COL, 1)),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3)),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64 * 64),\n",
    "        layers.Dropout(rate=0.4),\n",
    "        layers.Dense(10),\n",
    "        layers.Activation('softmax')\n",
    "    ]\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    for layer in struct:\n",
    "        model.add(layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training a model\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "def train(X, Y, model_name='mnist_cnn_clean.model'):\n",
    "    \"\"\"\n",
    "    Train a model over given training set,\n",
    "    then save the trained model.\n",
    "    :param: model - the keras model to train\n",
    "    :param: train_set - Tuple of the training set, includes training samples and corresponding desired labels.\n",
    "    :param: val_set - Tuple of the validation set, includes samples and desired labels.\n",
    "    :param: model_name - the name used to save the trained model.\n",
    "    :return: na\n",
    "    \"\"\"\n",
    "    nb_train = int(len(X) * VAL_RATE)\n",
    "    train_samples = X[:-nb_train]\n",
    "    train_classes = Y[:-nb_train]\n",
    "    val_samples = X[-nb_train:]\n",
    "    val_classes = Y[-nb_train:]\n",
    "    \n",
    "    model = cnn()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "    # Train the model\n",
    "    print(\"Training {}...\".format(model_name))\n",
    "    model.fit(train_samples, train_classes, epochs=1,\n",
    "              batch_size=BATCH_SIZE, shuffle=True,\n",
    "              verbose=1, validation_data=(val_samples, val_classes))\n",
    "     \n",
    "    # Save the model\n",
    "    #model.save(\"data/{}\".format(model_name))\n",
    "    models.save_model(model, \"data/{}\".format(model_name))\n",
    "    del model\n",
    "    \n",
    "    print(\"Trained model has been saved to data/{}\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implement algorithms generating adversarial examples\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "def fgsm(x, prediction, eps=0.15, y=None, clip_min=None, clip_max=None):\n",
    "    '''\n",
    "    Define the symbolic FGSM fitting tf framework\n",
    "    '''\n",
    "    if y is None:\n",
    "        y = tf.cast(tf.equal(prediction, \n",
    "                                tf.reduce_max(prediction, 1, keepdims=True)), tf.float32)\n",
    "        \n",
    "    y /= tf.reduce_sum(y, 1, keepdims=True)\n",
    "    \n",
    "    logits, = prediction.op.inputs\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y))\n",
    "    \n",
    "    grad, = tf.gradients(loss, x)\n",
    "    perturbation = eps * tf.sign(grad)\n",
    "    adv_sample = tf.stop_gradient(x + perturbation)\n",
    "    \n",
    "    # clip if it's required\n",
    "    if (clip_min is not None) and (clip_max is not None):\n",
    "        adv_sample = tf.clip_by_value(adv_sample, clip_min, clip_max)\n",
    "    \n",
    "    return adv_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Crafting adversarial examples.\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "def generate_adversarial(model_name, X, Y, attack_approach):\n",
    "    \"\"\"\n",
    "    Craft and save adversarial examples.\n",
    "    :param: model_name - the name of the target model\n",
    "    :param: X\n",
    "    :param: Y\n",
    "    :param: attack_approach - adversarial example generation algorithm to use\n",
    "    :param: adv_file_name - the file name used to save the generated adversarial exmaples\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        tf_K.set_session(sess)\n",
    "        tf_K.set_learning_phase(0)\n",
    "        \n",
    "        # define tf placeholders and operations\n",
    "        x = tf.placeholder(tf.float32, shape = (None,) + X.shape[1:])\n",
    "        y = tf.placeholder(tf.float32, shape = (None,) + Y.shape[1:])\n",
    "\n",
    "        # load model\n",
    "        print('loading model {}...'.format(model_name))\n",
    "        model = load_model(\"data/{}\".format(model_name))\n",
    "        adv_file_name = model_name.split('.')[0]\n",
    "\n",
    "        # model accuracy\n",
    "        _, acc_original = model.evaluate(X, Y, batch_size=BATCH_SIZE, verbose=0)\n",
    "        print('test acc (on original): {}'.format(acc_original))\n",
    "        print('Generating adversarial examples using {}, it will take some time...'.format(attack_approach))\n",
    "        \n",
    "        if attack_approach == 'fgsm':\n",
    "            adv_file_name = '{}_{}_eps{}.npy'.format(adv_file_name, attack_approach, int(eps * 100))\n",
    "\n",
    "            # symbolic fgsm\n",
    "            x_adv = fgsm(x, model(x), eps=eps, y=y, clip_min=None, clip_max=None)\n",
    "\n",
    "            # craft adversarial examples\n",
    "            X_adv, = batch_eval(sess, [x, y], [x_adv], [X, Y], batch_size=BATCH_SIZE)\n",
    "        elif attack_approach == 'jsma':\n",
    "            raise NotImplementedError('Not ready yet.')\n",
    "        else:\n",
    "            raise ValueError('{} is not supported.'.format(attack_approach))\n",
    "\n",
    "        # test accuracy on adversarial examples\n",
    "        _, acc_adv = model.evaluate(X_adv, Y, batch_size=BATCH_SIZE, verbose=0)\n",
    "        print ('test acc (on adversarial): {} - (epsilon: {})'.format(acc_adv, eps))\n",
    "        print('adv:', X.shape, X_adv.shape, Y.shape)\n",
    "                \n",
    "        # save the generated adversarial examples\n",
    "        np.save(\"data/orig_{}\".format(adv_file_name), X)\n",
    "        np.save(\"data/adv_{}\".format(adv_file_name), X_adv)\n",
    "        np.save(\"data/label_{}\".format(adv_file_name), Y)\n",
    "        print(\"adversarial examples were generated and saved to data/*_{}\".format(adv_file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\'def affine_trans(original_images, transformation):\\n    \"\"\"\\n    Apply affine transformation on images.\\n    :param: original_images - the images to applied transformations on.\\n    :param: transformation - the standard transformation to apply.\\n    :return: the transformed dataset.\\n    \"\"\"\\n    print(\\'Applying affine transformation on images({})...\\'.format(transformation))\\n    \\n    # -----------------------------------------\\n    # In affine transformation, all parallel lines in the original image\\n    # will still be parallel in the transformed image.\\n    # To find the transformation matrix, we need to specify 3 points\\n    # from the original image and their corresponding locations in transformed image.\\n    # Then, the transformation matrix M (2x3) can be generated by getAffineTransform():\\n    # -----------------------------------------\\n    \\n    point1 = [0.25 * IMG_COL, 0.25 * IMG_ROW]\\n    point2 = [0.25 * IMG_COL, 0.5 * IMG_ROW]\\n    point3 = [0.5 * IMG_COL, 0.25 * IMG_ROW]\\n    \\n    pts_original = np.float32([point1, point2, point3])\\n        \\n    if (transformation == \\'affine_vertical_compress\\'):\\n        point1 = [0.25 * IMG_COL, 0.25 * IMG_ROW]\\n        point2 = [0.25 * IMG_COL, 0.4 * IMG_ROW]\\n        point3 = [0.5 * IMG_COL, 0.25 * IMG_ROW]\\n    elif (transformation == \\'affine_vertical_stretch\\'):\\n        point1 = [0.25 * IMG_COL, 0.25 * IMG_ROW]\\n        point2 = [0.25 * IMG_COL, 0.6 * IMG_ROW]\\n        point3 = [0.5 * IMG_COL, 0.25 * IMG_ROW]\\n    elif (transformation == \\'affine_horizontal_compress\\'):\\n        point1 = [0.25 * IMG_COL, 0.25 * IMG_ROW]\\n        point2 = [0.25 * IMG_COL, 0.5 * IMG_ROW]\\n        point3 = [0.4 * IMG_COL, 0.25 * IMG_ROW]\\n    elif (transformation == \\'affine_horizontal_stretch\\'):\\n        point1 = [0.25 * IMG_COL, 0.25 * IMG_ROW]\\n        point2 = [0.25 * IMG_COL, 0.5 * IMG_ROW]\\n        point3 = [0.6 * IMG_COL, 0.25 * IMG_ROW]\\n    elif (transformation == \\'affine_both_compress\\'):\\n        point1 = [0.25 * IMG_COL, 0.25 * IMG_ROW]\\n        point2 = [0.25 * IMG_COL, 0.4 * IMG_ROW]\\n        point3 = [0.4 * IMG_COL, 0.25 * IMG_ROW]\\n    elif (transformation == \\'affine_both_stretch\\'):\\n        point1 = [0.25 * IMG_COL, 0.25 * IMG_ROW]\\n        point2 = [0.25 * IMG_COL, 0.6 * IMG_ROW]\\n        point3 = [0.6 * IMG_COL, 0.25 * IMG_ROW]\\n    else:\\n        raise ValueError(\\'{} is not supported.\\'.format(transformation))\\n    \\n    transformed_images = []\\n    \\n    # define transformation matrix\\n    pts_transformed = np.float32([point1, point2, point3])\\n    trans_matrix = cv2.getAffineTransform(pts_original, pts_transformed)\\n    \\n    # applying an affine transformation over the dataset\\n    transformed_images = np.zeros_like(original_images)\\n    for i in range(original_images.shape[0]):\\n        transformed_images[i] = np.expand_dims(cv2.warpAffine(original_images[i], trans_matrix, \\n                                                              (IMG_COL, IMG_ROW)), axis=2)\\n\\n    print(\\'Applied transformation {}.\\'.format(transformation))\\n        \\n    # for debugging\\n    if debug:\\n        for i in range(5):\\n            cv2.imshow(\\'clean image\\', original_images[i].reshape(IMG_ROW, IMG_COL))\\n            cv2.waitKey(0)\\n            cv2.destroyAllWindows()\\n            cv2.imshow(transformation, transformed_images[i])\\n            cv2.waitKey(0)\\n            cv2.destroyAllWindows()\\n    return transformed_images\\n\\n# for debugging\\nif debug:\\n    (X_train, _), _ = load_mnist()\\n    X_train = X_train[:5]\\n    affine_trans(X_train, \\'affine_both_compress\\')'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Image processing - applying affine transformation on image.\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "''''def affine_trans(original_images, transformation):\n",
    "    \"\"\"\n",
    "    Apply affine transformation on images.\n",
    "    :param: original_images - the images to applied transformations on.\n",
    "    :param: transformation - the standard transformation to apply.\n",
    "    :return: the transformed dataset.\n",
    "    \"\"\"\n",
    "    print('Applying affine transformation on images({})...'.format(transformation))\n",
    "    \n",
    "    # -----------------------------------------\n",
    "    # In affine transformation, all parallel lines in the original image\n",
    "    # will still be parallel in the transformed image.\n",
    "    # To find the transformation matrix, we need to specify 3 points\n",
    "    # from the original image and their corresponding locations in transformed image.\n",
    "    # Then, the transformation matrix M (2x3) can be generated by getAffineTransform():\n",
    "    # -----------------------------------------\n",
    "    \n",
    "    point1 = [0.25 * IMG_COL, 0.25 * IMG_ROW]\n",
    "    point2 = [0.25 * IMG_COL, 0.5 * IMG_ROW]\n",
    "    point3 = [0.5 * IMG_COL, 0.25 * IMG_ROW]\n",
    "    \n",
    "    pts_original = np.float32([point1, point2, point3])\n",
    "        \n",
    "    if (transformation == 'affine_vertical_compress'):\n",
    "        point1 = [0.25 * IMG_COL, 0.25 * IMG_ROW]\n",
    "        point2 = [0.25 * IMG_COL, 0.4 * IMG_ROW]\n",
    "        point3 = [0.5 * IMG_COL, 0.25 * IMG_ROW]\n",
    "    elif (transformation == 'affine_vertical_stretch'):\n",
    "        point1 = [0.25 * IMG_COL, 0.25 * IMG_ROW]\n",
    "        point2 = [0.25 * IMG_COL, 0.6 * IMG_ROW]\n",
    "        point3 = [0.5 * IMG_COL, 0.25 * IMG_ROW]\n",
    "    elif (transformation == 'affine_horizontal_compress'):\n",
    "        point1 = [0.25 * IMG_COL, 0.25 * IMG_ROW]\n",
    "        point2 = [0.25 * IMG_COL, 0.5 * IMG_ROW]\n",
    "        point3 = [0.4 * IMG_COL, 0.25 * IMG_ROW]\n",
    "    elif (transformation == 'affine_horizontal_stretch'):\n",
    "        point1 = [0.25 * IMG_COL, 0.25 * IMG_ROW]\n",
    "        point2 = [0.25 * IMG_COL, 0.5 * IMG_ROW]\n",
    "        point3 = [0.6 * IMG_COL, 0.25 * IMG_ROW]\n",
    "    elif (transformation == 'affine_both_compress'):\n",
    "        point1 = [0.25 * IMG_COL, 0.25 * IMG_ROW]\n",
    "        point2 = [0.25 * IMG_COL, 0.4 * IMG_ROW]\n",
    "        point3 = [0.4 * IMG_COL, 0.25 * IMG_ROW]\n",
    "    elif (transformation == 'affine_both_stretch'):\n",
    "        point1 = [0.25 * IMG_COL, 0.25 * IMG_ROW]\n",
    "        point2 = [0.25 * IMG_COL, 0.6 * IMG_ROW]\n",
    "        point3 = [0.6 * IMG_COL, 0.25 * IMG_ROW]\n",
    "    else:\n",
    "        raise ValueError('{} is not supported.'.format(transformation))\n",
    "    \n",
    "    transformed_images = []\n",
    "    \n",
    "    # define transformation matrix\n",
    "    pts_transformed = np.float32([point1, point2, point3])\n",
    "    trans_matrix = cv2.getAffineTransform(pts_original, pts_transformed)\n",
    "    \n",
    "    # applying an affine transformation over the dataset\n",
    "    transformed_images = np.zeros_like(original_images)\n",
    "    for i in range(original_images.shape[0]):\n",
    "        transformed_images[i] = np.expand_dims(cv2.warpAffine(original_images[i], trans_matrix, \n",
    "                                                              (IMG_COL, IMG_ROW)), axis=2)\n",
    "\n",
    "    print('Applied transformation {}.'.format(transformation))\n",
    "        \n",
    "    # for debugging\n",
    "    if debug:\n",
    "        for i in range(5):\n",
    "            cv2.imshow('clean image', original_images[i].reshape(IMG_ROW, IMG_COL))\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            cv2.imshow(transformation, transformed_images[i])\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "    return transformed_images\n",
    "\n",
    "# for debugging\n",
    "if debug:\n",
    "    (X_train, _), _ = load_mnist()\n",
    "    X_train = X_train[:5]\n",
    "    affine_trans(X_train, 'affine_both_compress')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def flip(original_images, transformation):\\n    \"\"\"\\n    Flip images.\\n    :param: original_images - the images to applied transformations on.\\n    :param: transformation - the standard transformation to apply.\\n    :return: the transformed dataset.\\n    \"\"\"\\n    print(\\'Flipping images({})...\\'.format(transformation))\\n    \\n    transformed_images = np.zeros_like(original_images)\\n    \\n    # set flipping direction\\n    flip_direction = 0\\n    if transformation == \\'vertical_flip\\':\\n        # flip around the x-axis\\n        flip_direction = 0\\n    elif transformation == \\'horizontal_flip\\':\\n        # flip around the y-axis\\n        flip_direction = 1\\n    elif transformation == \\'both_flip\\':\\n        # flip around both axes\\n        flip_direction = -1\\n    else:\\n        raise ValueError(\\'{} is not supported.\\'.format(transformation))\\n    \\n    # flip images\\n    for i in range(original_images.shape[0]):\\n        transformed_images[i] = np.expand_dims(cv2.flip(original_images[i], flip_direction), axis=2)\\n    \\n    # for debugging\\n    if debug:\\n        for i in range(5):\\n            cv2.imshow(\\'clean image\\', original_images[i].reshape(IMG_ROW, IMG_COL))\\n            cv2.waitKey(0)\\n            cv2.destroyAllWindows()\\n\\n            cv2.imshow(transformation, transformed_images[i])\\n            cv2.waitKey(0)\\n            cv2.destroyAllWindows()\\n    return transformed_images\\n\\n# for debugging\\nif debug:\\n    (X_train, _), _ = load_mnist()\\n    X_train = X_train[:5]\\n    flip(X_train, \\'both_flip\\')'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Image processing - flip image\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "\n",
    "'''def flip(original_images, transformation):\n",
    "    \"\"\"\n",
    "    Flip images.\n",
    "    :param: original_images - the images to applied transformations on.\n",
    "    :param: transformation - the standard transformation to apply.\n",
    "    :return: the transformed dataset.\n",
    "    \"\"\"\n",
    "    print('Flipping images({})...'.format(transformation))\n",
    "    \n",
    "    transformed_images = np.zeros_like(original_images)\n",
    "    \n",
    "    # set flipping direction\n",
    "    flip_direction = 0\n",
    "    if transformation == 'vertical_flip':\n",
    "        # flip around the x-axis\n",
    "        flip_direction = 0\n",
    "    elif transformation == 'horizontal_flip':\n",
    "        # flip around the y-axis\n",
    "        flip_direction = 1\n",
    "    elif transformation == 'both_flip':\n",
    "        # flip around both axes\n",
    "        flip_direction = -1\n",
    "    else:\n",
    "        raise ValueError('{} is not supported.'.format(transformation))\n",
    "    \n",
    "    # flip images\n",
    "    for i in range(original_images.shape[0]):\n",
    "        transformed_images[i] = np.expand_dims(cv2.flip(original_images[i], flip_direction), axis=2)\n",
    "    \n",
    "    # for debugging\n",
    "    if debug:\n",
    "        for i in range(5):\n",
    "            cv2.imshow('clean image', original_images[i].reshape(IMG_ROW, IMG_COL))\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "            cv2.imshow(transformation, transformed_images[i])\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "    return transformed_images\n",
    "\n",
    "# for debugging\n",
    "if debug:\n",
    "    (X_train, _), _ = load_mnist()\n",
    "    X_train = X_train[:5]\n",
    "    flip(X_train, 'both_flip')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def rotate(original_images, transformation):\\n    \"\"\"\\n    Rotate images.\\n    :param: original_images - the images to applied transformations on.\\n    :param: transformation - the standard transformation to apply.\\n    :return: the transformed dataset.\\n    \"\"\"\\n    print(\\'Rotating images({})...\\'.format(transformation))\\n    trans_matrix = None\\n    \\n    transformed_images = []\\n    center = (IMG_ROW/2, IMG_COL/2)\\n    \\n    # ---------------\\n    # rotate images\\n    # ---------------\\n    if transformation == \\'rotate90\\':\\n        # rotate 90-deg counterclockwise\\n        angle = 90\\n        scale = 1.0\\n\\n        trans_matrix = cv2.getRotationMatrix2D(center, angle, scale)\\n    elif transformation == \\'rotate180\\':\\n        # rotate 180-deg counterclockwise\\n        angle = 180\\n        scale = 1.0\\n        \\n        trans_matrix = cv2.getRotationMatrix2D(center, angle, scale)\\n    elif transformation == \\'rotate270\\':\\n        # rotate 270-deg counterclockwise\\n        angle = 270\\n        scale = 1.0\\n        \\n        trans_matrix = cv2.getRotationMatrix2D(center, angle, scale)\\n    else:\\n        raise ValueError(\\'{} is not supported.\\'.format(transformation))\\n    \\n    # applying an affine transformation over the dataset\\n    transformed_images = np.zeros_like(original_images)\\n    for i in range(original_images.shape[0]):\\n        transformed_images[i] = np.expand_dims(cv2.warpAffine(original_images[i], trans_matrix, \\n                                                              (IMG_COL, IMG_ROW)), axis=2)\\n\\n    print(\\'Applied transformation {}.\\'.format(transformation))\\n        \\n    # for debugging\\n    if debug:\\n        for i in range(5):\\n            cv2.imshow(\\'clean image\\', original_images[i].reshape(IMG_ROW, IMG_COL))\\n            cv2.waitKey(0)\\n            cv2.destroyAllWindows()\\n\\n            cv2.imshow(transformation, transformed_images[i])\\n            cv2.waitKey(0)\\n            cv2.destroyAllWindows()\\n    return transformed_images\\n\\n# for debugging\\nif debug:\\n    (X_train, _), _ = load_mnist()\\n    X_train = X_train[:5]\\n    rotate(X_train, \\'rotate270\\')'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Image processing - rotate image.\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "'''def rotate(original_images, transformation):\n",
    "    \"\"\"\n",
    "    Rotate images.\n",
    "    :param: original_images - the images to applied transformations on.\n",
    "    :param: transformation - the standard transformation to apply.\n",
    "    :return: the transformed dataset.\n",
    "    \"\"\"\n",
    "    print('Rotating images({})...'.format(transformation))\n",
    "    trans_matrix = None\n",
    "    \n",
    "    transformed_images = []\n",
    "    center = (IMG_ROW/2, IMG_COL/2)\n",
    "    \n",
    "    # ---------------\n",
    "    # rotate images\n",
    "    # ---------------\n",
    "    if transformation == 'rotate90':\n",
    "        # rotate 90-deg counterclockwise\n",
    "        angle = 90\n",
    "        scale = 1.0\n",
    "\n",
    "        trans_matrix = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    elif transformation == 'rotate180':\n",
    "        # rotate 180-deg counterclockwise\n",
    "        angle = 180\n",
    "        scale = 1.0\n",
    "        \n",
    "        trans_matrix = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    elif transformation == 'rotate270':\n",
    "        # rotate 270-deg counterclockwise\n",
    "        angle = 270\n",
    "        scale = 1.0\n",
    "        \n",
    "        trans_matrix = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    else:\n",
    "        raise ValueError('{} is not supported.'.format(transformation))\n",
    "    \n",
    "    # applying an affine transformation over the dataset\n",
    "    transformed_images = np.zeros_like(original_images)\n",
    "    for i in range(original_images.shape[0]):\n",
    "        transformed_images[i] = np.expand_dims(cv2.warpAffine(original_images[i], trans_matrix, \n",
    "                                                              (IMG_COL, IMG_ROW)), axis=2)\n",
    "\n",
    "    print('Applied transformation {}.'.format(transformation))\n",
    "        \n",
    "    # for debugging\n",
    "    if debug:\n",
    "        for i in range(5):\n",
    "            cv2.imshow('clean image', original_images[i].reshape(IMG_ROW, IMG_COL))\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "            cv2.imshow(transformation, transformed_images[i])\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "    return transformed_images\n",
    "\n",
    "# for debugging\n",
    "if debug:\n",
    "    (X_train, _), _ = load_mnist()\n",
    "    X_train = X_train[:5]\n",
    "    rotate(X_train, 'rotate270')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def shift(original_images, transformation):\\n    \"\"\"\\n    Shift images.\\n    :param: original_images - the images to applied transformations on.\\n    :param: transformation - the standard transformation to apply.\\n    :return: the transformed dataset.\\n    \"\"\"\\n    print(\\'Shifting images({})...\\'.format(transformation))\\n    \\n    # -----------------------------------------\\n    # Shift images in (tx, ty) direction, by 15% of width and/or height.\\n    # Given shift direction (tx, ty), we can create the\\n    # transformation matrix M as follows:\\n    #\\n    # M = [[1, 0, tx],\\n    #      [0, 1, ty]]\\n    #\\n    # -----------------------------------------\\n    tx = tf.cast(0.15 * IMG_COL, tf.int32)\\n    ty = tf.cast(0.15 * IMG_ROW, tf.int32)\\n    \\n    if transformation == \\'shift_left\\':\\n        tx = 0 - tx\\n        ty = 0\\n    elif transformation == \\'shift_right\\':\\n        tx = tx\\n        ty = 0\\n    elif transformation == \\'shift_up\\':\\n        tx = 0\\n        ty = 0 - ty\\n    elif transformation == \\'shift_down\\':\\n        tx = 0\\n        ty = ty\\n    elif transformation == \\'shift_top_right\\':\\n        tx = tx\\n        ty = 0 - ty\\n    elif transformation == \\'shift_top_left\\':\\n        tx = 0 - tx\\n        ty = 0 - ty\\n    elif transformation == \\'shift_bottom_left\\':\\n        tx = 0 - tx\\n        ty = ty\\n    elif transformation == \\'shift_bottom_right\\':\\n        tx = tx\\n        ty = ty\\n    else:\\n        raise ValueError(\\'{} is not supported.\\'.format(transformation))\\n    \\n    transformed_images = []\\n    center = (IMG_ROW/2, IMG_COL/2)\\n    \\n    # define transformation matrix\\n    trans_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\\n    \\n    # applying an affine transformation over the dataset\\n    transformed_images = np.zeros_like(original_images)\\n    for i in range(original_images.shape[0]):\\n        transformed_images[i] = np.expand_dims(cv2.warpAffine(original_images[i], trans_matrix, \\n                                                              (IMG_COL, IMG_ROW)), axis=2)\\n\\n    print(\\'Applied transformation {}.\\'.format(transformation))\\n        \\n    # for debugging\\n    if debug:\\n        for i in range(5):\\n            cv2.imshow(\\'clean image\\', original_images[i].reshape(IMG_ROW, IMG_COL))\\n            cv2.waitKey(0)\\n            cv2.destroyAllWindows()\\n\\n            cv2.imshow(transformation, transformed_images[i])\\n            cv2.waitKey(0)\\n            cv2.destroyAllWindows()\\n    return transformed_images\\n\\n# for debugging\\nif debug:\\n    (X_train, _), _ = load_mnist()\\n    X_train = X_train[:10]\\n    shift(X_train, \\'shift_bottom_right\\')'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Image processing - shifting image.\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "'''def shift(original_images, transformation):\n",
    "    \"\"\"\n",
    "    Shift images.\n",
    "    :param: original_images - the images to applied transformations on.\n",
    "    :param: transformation - the standard transformation to apply.\n",
    "    :return: the transformed dataset.\n",
    "    \"\"\"\n",
    "    print('Shifting images({})...'.format(transformation))\n",
    "    \n",
    "    # -----------------------------------------\n",
    "    # Shift images in (tx, ty) direction, by 15% of width and/or height.\n",
    "    # Given shift direction (tx, ty), we can create the\n",
    "    # transformation matrix M as follows:\n",
    "    #\n",
    "    # M = [[1, 0, tx],\n",
    "    #      [0, 1, ty]]\n",
    "    #\n",
    "    # -----------------------------------------\n",
    "    tx = tf.cast(0.15 * IMG_COL, tf.int32)\n",
    "    ty = tf.cast(0.15 * IMG_ROW, tf.int32)\n",
    "    \n",
    "    if transformation == 'shift_left':\n",
    "        tx = 0 - tx\n",
    "        ty = 0\n",
    "    elif transformation == 'shift_right':\n",
    "        tx = tx\n",
    "        ty = 0\n",
    "    elif transformation == 'shift_up':\n",
    "        tx = 0\n",
    "        ty = 0 - ty\n",
    "    elif transformation == 'shift_down':\n",
    "        tx = 0\n",
    "        ty = ty\n",
    "    elif transformation == 'shift_top_right':\n",
    "        tx = tx\n",
    "        ty = 0 - ty\n",
    "    elif transformation == 'shift_top_left':\n",
    "        tx = 0 - tx\n",
    "        ty = 0 - ty\n",
    "    elif transformation == 'shift_bottom_left':\n",
    "        tx = 0 - tx\n",
    "        ty = ty\n",
    "    elif transformation == 'shift_bottom_right':\n",
    "        tx = tx\n",
    "        ty = ty\n",
    "    else:\n",
    "        raise ValueError('{} is not supported.'.format(transformation))\n",
    "    \n",
    "    transformed_images = []\n",
    "    center = (IMG_ROW/2, IMG_COL/2)\n",
    "    \n",
    "    # define transformation matrix\n",
    "    trans_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "    \n",
    "    # applying an affine transformation over the dataset\n",
    "    transformed_images = np.zeros_like(original_images)\n",
    "    for i in range(original_images.shape[0]):\n",
    "        transformed_images[i] = np.expand_dims(cv2.warpAffine(original_images[i], trans_matrix, \n",
    "                                                              (IMG_COL, IMG_ROW)), axis=2)\n",
    "\n",
    "    print('Applied transformation {}.'.format(transformation))\n",
    "        \n",
    "    # for debugging\n",
    "    if debug:\n",
    "        for i in range(5):\n",
    "            cv2.imshow('clean image', original_images[i].reshape(IMG_ROW, IMG_COL))\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "            cv2.imshow(transformation, transformed_images[i])\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "    return transformed_images\n",
    "\n",
    "# for debugging\n",
    "if debug:\n",
    "    (X_train, _), _ = load_mnist()\n",
    "    X_train = X_train[:10]\n",
    "    shift(X_train, 'shift_bottom_right')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(MNIST) summary:\n",
      "Train set: (60000, 28, 28, 1), (60000, 10)\n",
      "Test set: (10000, 28, 28, 1), (10000, 10)\n",
      "Applying morphological transformation (closing)...\n",
      "Applied transformation closing.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Image processing - morphological transformations.\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "def morph_trans(original_images, transformation):\n",
    "    \"\"\"\n",
    "    Apply morphological transformations on images.\n",
    "    :param: original_images - the images to applied transformations on.\n",
    "    :param: transformation - the standard transformation to apply.\n",
    "    :return: the transformed dataset.\n",
    "    \"\"\"\n",
    "    print('Applying morphological transformation ({})...'.format(transformation))\n",
    "    \n",
    "    transformed_images = np.zeros_like(original_images)\n",
    "    \n",
    "    # set kernel as a matrix of size 2\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    \n",
    "    if transformation == 'dilation':\n",
    "        # min filter (Graphics Mill)\n",
    "        # It's opposite of erosion (max filter)\n",
    "        # In dilation, a pixel element is '1' if at least one pixel\n",
    "        # under the kernel is '1'. So it increases the white region\n",
    "        # in the image or size of foreground object increases.\n",
    "        for i in range(original_images.shape[0]):\n",
    "            transformed_images[i] = np.expand_dims(cv2.dilate(original_images[i], \n",
    "                                                              kernel, iterations=1), axis=2)\n",
    "    elif transformation == 'erosion':\n",
    "        # max filter (Graphic Mill)\n",
    "        # The basic idea of erosion is like soil erosion.\n",
    "        # It erodes away the boundaries of foreground object\n",
    "        # (always try to keep foreground in white)\n",
    "        # The kernel slides through the image as in 2D convolution.\n",
    "        # A pixel in the original image will be considered 1 only if\n",
    "        # all the pixels under the kernel is 1, otherwise, it's eroded.\n",
    "        for i in range(original_images.shape[0]):\n",
    "            transformed_images[i] = np.expand_dims(cv2.erode(original_images[i], \n",
    "                                                              kernel, iterations=1), axis=2)\n",
    "    elif transformation == 'opening':\n",
    "        # erosion followed by dilation\n",
    "        for i in range(original_images.shape[0]):\n",
    "            transformed_images[i] = np.expand_dims(cv2.morphologyEx(original_images[i], \n",
    "                                                              cv2.MORPH_OPEN, kernel), axis=2)\n",
    "    elif transformation == 'closing':\n",
    "        # erosion followed by dilation\n",
    "        for i in range(original_images.shape[0]):\n",
    "            transformed_images[i] = np.expand_dims(cv2.morphologyEx(original_images[i], \n",
    "                                                              cv2.MORPH_CLOSE, kernel), axis=2)\n",
    "    elif transformation == 'gradient':\n",
    "        # keep the outline of the object\n",
    "        for i in range(original_images.shape[0]):\n",
    "            transformed_images[i] = np.expand_dims(cv2.morphologyEx(original_images[i], \n",
    "                                                              cv2.MORPH_GRADIENT, kernel), axis=2)\n",
    "    else:\n",
    "        raise ValueError('{} is not supported.'.format(transformation))\n",
    "    \n",
    "    print('Applied transformation {}.'.format(transformation))\n",
    "        \n",
    "    # for debugging\n",
    "    if debug:\n",
    "        for i in range(5):\n",
    "            cv2.imshow('clean image', original_images[i].reshape(IMG_ROW, IMG_COL))\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "            cv2.imshow(transformation, transformed_images[i])\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "    return transformed_images\n",
    "\n",
    "# for debugging\n",
    "if debug:\n",
    "    (X_train, _), _ = load_mnist()\n",
    "    X_train = X_train[:5]\n",
    "    morph_trans(X_train, 'closing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Image processing - image thresholding\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "\n",
    "# def thresholding(original_images, transformation):\n",
    "#     \"\"\"\n",
    "#     Image thresholding.\n",
    "#     :param: original_images - the images to applied transformations on.\n",
    "#     :param: transformation - the standard transformation to apply.\n",
    "#     :return: the transformed dataset.\n",
    "#     \"\"\"\n",
    "#     print('Applying image thresholding({})...'.format(transformation))\n",
    "    \n",
    "#     transformed_images = np.zeros_like(original_images)\n",
    "        \n",
    "#     if transformation == 'thresh_binary':\n",
    "#         # \n",
    "#         for i in range(original_images.shape[0]):\n",
    "#             _, transformed_images[i] = np.expand_dims(cv2.threshold(original_images[i],\n",
    "#                                                                     127, 255, cv2.THRESH_BINARY), axis=2)\n",
    "#     elif transformation == 'thresh_mean':\n",
    "#         # \n",
    "#         for i in range(original_images.shape[0]):\n",
    "#             transformed_images[i] = np.expand_dims(cv2.adaptiveThreshold(original_images[i],\n",
    "#                                                                          255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "#                                                                         cv2.THRESH_BINARY, 11, 2), axis=2)\n",
    "#     elif transformation == 'thresh_gaussian':\n",
    "#         # \n",
    "#         for i in range(original_images.shape[0]):\n",
    "#             transformed_images[i] = np.expand_dims(cv2.adaptiveThreshold(original_images[i],\n",
    "#                                                                          255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "#                                                                         cv2.THRESH_BINARY, 11, 2), axis=2)\n",
    "#     else:\n",
    "#         raise ValueError('{} is not supported.'.format(transformation))\n",
    "    \n",
    "#     print('Applied transformation {}.'.format(transformation))\n",
    "        \n",
    "#     # for debugging\n",
    "#     if debug:\n",
    "#         for i in range(5):\n",
    "#             cv2.imshow('clean image', original_images[i].reshape(IMG_ROW, IMG_COL))\n",
    "#             cv2.waitKey(0)\n",
    "#             cv2.destroyAllWindows()\n",
    "\n",
    "#             cv2.imshow(transformation, transformed_images[i])\n",
    "#             cv2.waitKey(0)\n",
    "#             cv2.destroyAllWindows()\n",
    "#     return transformed_images\n",
    "\n",
    "# # for debugging\n",
    "# if debug:\n",
    "#     (X_train, _), _ = load_mnist()\n",
    "#     X_train = X_train[:5]\n",
    "#     thresholding(X_train, 'thresh_binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Image processing - image augmentation\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "# M_IMG_AUGMNT = ['samplewise_std_norm', 'feature_std_norm', 'zca_whitening', 'pca_whitening']\n",
    "\n",
    "def augmentation(X, Y, transformation):\n",
    "    \"\"\"\n",
    "    Image augmentation.\n",
    "    :param: original_images - the images to applied transformations on.\n",
    "    :param: transformation - the standard transformation to apply.\n",
    "    :return: the transformed dataset.\n",
    "    \"\"\"\n",
    "    print('Applying image augmentation({})...'.format(transformation))\n",
    "    \n",
    "    data_generator = None\n",
    "    \n",
    "    #transformed_images = np.zeros_like(original_images)\n",
    "    transformed_images = []\n",
    "    transformed_labels = []\n",
    "        \n",
    "    if transformation == 'samplewise_std_norm':\n",
    "        data_generator = ImageDataGenerator(samplewise_center=True, \n",
    "                                            samplewise_std_normalization=True)\n",
    "    elif transformation == 'feature_std_norm':\n",
    "        data_generator = ImageDataGenerator(featurewise_center=True, \n",
    "                                            featurewise_std_normalization=True)\n",
    "    elif transformation == 'zca_whitening':\n",
    "        data_generator = ImageDataGenerator(zca_whitening=True)\n",
    "    elif transformation == 'pca_whitening':\n",
    "        raise NotImplementedError('{} is not ready yet.'.format(transformation))\n",
    "    else:\n",
    "        raise ValueError('{} is not supported.'.format(transformation))\n",
    "    \n",
    "    # fit parameters from data\n",
    "    data_generator.fit(X)\n",
    "    \n",
    "    for X_batch, Y_batch in data_generator.flow(X, Y, batch_size=64):\n",
    "        #cv2.imshow(transformation, X_batch[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            transformed_images.append(X_batch[i])\n",
    "            transformed_labels.append(Y_batch[i])\n",
    "        break\n",
    "        \n",
    "    print('Applied transformation {}.'.format(transformation))\n",
    "        \n",
    "    # for debugging\n",
    "    if debug:\n",
    "        for i in range(5):\n",
    "            cv2.imshow('clean image({})'.format(np.argmax(Y[i])), X[i].reshape(IMG_ROW, IMG_COL))\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "            cv2.imshow('{}({})'.format(transformation, np.argmax(transformed_labels[i])), transformed_images[i])\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "    return (transformed_images, transformed_labels)\n",
    "\n",
    "# for debugging\n",
    "if debug:\n",
    "    (X_train, Y_train), _ = load_mnist()\n",
    "    X_train = X_train[:5]\n",
    "    Y_train = Y_train[:5]\n",
    "    augmentation(X_train, Y_train, 'samplewise_std_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate a model\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "def evaluate(model_name, X, Y):\n",
    "    \"\"\"\n",
    "    Evaluate given model.\n",
    "    :param: model - the model to evaluate.\n",
    "    :param: X - the test set.\n",
    "    :param: Y - the desired labels associated with test examples.\n",
    "    :return: test accuracy, \n",
    "            average confidence for correctly classified examples, \n",
    "            average confidence for misclassified examples.\n",
    "    \"\"\"\n",
    "    correct_cnt = 0\n",
    "    nb_examples = 0\n",
    "    \n",
    "    test_acc = 0.\n",
    "    conf = 0.\n",
    "    conf_misclassified = 0.\n",
    "    \n",
    "    model = load_model('data/{}'.format(model_name))\n",
    "    \n",
    "    pred_probs = model.predict(X, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # iterate over test set\n",
    "    for pred_prob, true_prob in zip(pred_probs, Y):\n",
    "        nb_examples += 1\n",
    "        \n",
    "        pred_label = np.argmax(pred_prob)\n",
    "        true_label = np.argmax(true_prob)\n",
    "        \n",
    "        if (pred_label == true_label):\n",
    "            correct_cnt += 1\n",
    "            conf += np.max(pred_prob)\n",
    "        else:\n",
    "            conf_misclassified += np.max(pred_prob)\n",
    "    \n",
    "    # test accuracy\n",
    "    test_acc = (1.0 * correct_cnt) / nb_examples\n",
    "    \n",
    "    # average confidece for correctly classified examples\n",
    "    avg_conf = conf / correct_cnt\n",
    "    \n",
    "    # average confidence for misclassified examples\n",
    "    avg_conf_misclassified = conf_misclassified / (nb_examples - correct_cnt)\n",
    "    \n",
    "    return test_acc, avg_conf, avg_conf_misclassified    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate an attack\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "def evaluate_attack(model_name, adv_file_name, transformation):\n",
    "    \"\"\"\n",
    "    Evaluate attack approach\n",
    "    :param: model_name - name of the target model.\n",
    "    :param: X - the original test set.\n",
    "    :param: Y - the desired labels associated with test examples.\n",
    "    :param: adv_file_name - name of the adversarial example file.\n",
    "    :return: test accuracy,\n",
    "            average confidence,\n",
    "            error rate\n",
    "    \"\"\"\n",
    "    # load model\n",
    "    print('loading model {}...'.format(model_name))\n",
    "    model = load_model('data/{}'.format(model_name))\n",
    "    \n",
    "    cnt_correct = 0\n",
    "    nb_legitimates = 0\n",
    "    cnt_miss = 0\n",
    "    \n",
    "    test_acc = 0.\n",
    "    conf = 0.\n",
    "    err_rate = 0.\n",
    "    \n",
    "    print('loading adversarial examples {}...'.format(adv_file_name))\n",
    "    X = np.load('data/orig_{}'.format(adv_file_name))\n",
    "    X_adv = np.load('data/adv_{}'.format(adv_file_name))\n",
    "    Y = np.load('data/label_{}'.format(adv_file_name))\n",
    "    Y_trans = []\n",
    "    \n",
    "    print(X.shape, X_adv.shape, Y.shape)\n",
    "    \n",
    "    print('Evaluating {} on {}-{}...'.format(model_name, transformation, adv_file_name))\n",
    "    \n",
    "    if (transformation in M_ROTATE):\n",
    "        X = rotate(X, transformation)\n",
    "        X_adv = rotate(X_adv, transformation)\n",
    "    elif (transformation in M_FLIP):\n",
    "        X = flip(X, transformation)\n",
    "        X_adv = flip(X_adv, transformation)\n",
    "    elif (transformation in M_SHIFT):\n",
    "        X = shift(X, transformation)\n",
    "        X_adv = shift(X_adv, transformation)\n",
    "    elif (transformation in M_AFFINE_TRANS):\n",
    "        X = affine_trans(X, transformation)\n",
    "        X_adv = affine_trans(X_adv, transformation)\n",
    "    elif (transformation in M_MORPH_TRANS):\n",
    "        X = morph_trans(X, transformation)\n",
    "        X_adv = morph_trans(X_adv, transformation)\n",
    "    elif (transformation in M_IMG_AUGMNT):\n",
    "        # TODO: after applied augmentations, the data were shuffled\n",
    "        (X, Y) = augmentation(X, Y, transformation)\n",
    "        (X_adv, Y_trans) = augmentation(X_adv, Y_trans, transformation)\n",
    "    \n",
    "    pred_probs = model.predict(X, batch_size=BATCH_SIZE)\n",
    "    pred_probs_adv = model.predict(X_adv, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    _, acc_original = model.evaluate(X, Y, batch_size=BATCH_SIZE, verbose=0)\n",
    "    _, acc_adv = model.evaluate(X_adv, Y, batch_size=BATCH_SIZE, verbose=0)\n",
    "    \n",
    "    print(acc_original, acc_adv)\n",
    "    \n",
    "    for pred_prob, pred_prob_adv, true_prob in zip(pred_probs, pred_probs_adv, Y):\n",
    "        pred_label = np.argmax(pred_prob)\n",
    "        pred_label_adv = np.argmax(pred_prob_adv)\n",
    "        true_label = np.argmax(true_prob)\n",
    "        \n",
    "        if (pred_label == true_label):\n",
    "            nb_legitimates += 1\n",
    "            if (pred_label_adv != pred_label):\n",
    "                conf += np.max(pred_prob_adv)\n",
    "                cnt_miss += 1\n",
    "            else:\n",
    "                cnt_correct += 1\n",
    "              \n",
    "    # error rate\n",
    "    miss_original = 1 - acc_original\n",
    "    miss_adv = 1 - acc_adv\n",
    "    err_rate = miss_adv - miss_original\n",
    "    \n",
    "    # average confidece for examples successfully attacked\n",
    "    avg_conf = conf / cnt_miss\n",
    "        \n",
    "    return acc_original, acc_adv, err_rate, avg_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training models: One over each transformed dataset.\n",
    "Then evaluating each trained models.\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "def training():\n",
    "    # training models\n",
    "    for transformation in tqdm(M):\n",
    "        model_name = 'mnist_cnn_{}.h5'.format(transformation)\n",
    "        print(\"Training model {}...\".format(model_name))\n",
    "        \n",
    "        (X_train, Y_train), _ = load_mnist()\n",
    "\n",
    "        if (transformation in M_ROTATE):\n",
    "            X_train = rotate(X_train, transformation)\n",
    "        elif (transformation in M_FLIP):\n",
    "            X_train = flip(X_train, transformation)\n",
    "        elif (transformation in M_SHIFT):\n",
    "            X_train = shift(X_train, transformation)\n",
    "        elif (transformation in M_AFFINE_TRANS):\n",
    "            X_train = affine_trans(X_train, transformation)\n",
    "        elif (transformation in M_MORPH_TRANS):\n",
    "            X_train = morph_trans(X_train, transformation)\n",
    "        elif (transformation in M_IMG_AUGMNT):\n",
    "            (X_train, Y_train) = augmentation(X_train, Y_train, transformation)\n",
    "        \n",
    "        # train the model\n",
    "        train(X_train, Y_train, model_name=model_name)\n",
    "        \n",
    "        print(\"---------------------------\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Crafting adversarial examples.\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "def crafting_adversarial_examples():\n",
    "    (X_train, Y_train), (X_test, Y_test) = load_mnist()\n",
    "    \n",
    "    for attack in tqdm(attacks):\n",
    "        #generate_adversarial('mnist_cnn_clean.h5', X_train, Y_train, attack)\n",
    "        generate_adversarial('mnist_cnn_clean.h5', X_test, Y_test, attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluating adversarial attacks.\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "def evaluating_attacks():\n",
    "    acc_models = []\n",
    "    acc_advs = []\n",
    "    ave_confs = []\n",
    "    error_rates = []\n",
    "    \n",
    "    # def evaluate_attack(model_name, X, Y, adv_file_name):\n",
    "    for attack in tqdm(attacks):\n",
    "        adv_file_name = 'mnist_cnn_clean_{}_eps{}.npy'.format(attack, int(eps * 100))\n",
    "\n",
    "        for trans in tqdm(M):\n",
    "            model_name = 'mnist_cnn_{}.h5'.format(trans)\n",
    "            acc, acc_adv, err_rate, conf = evaluate_attack(model_name, adv_file_name, trans)\n",
    "\n",
    "            acc_models.append(acc)\n",
    "            acc_advs.append(acc_adv)\n",
    "            ave_confs.append(conf)\n",
    "            error_rates.append(err_rate)\n",
    "\n",
    "    return acc_models, acc_advs, error_rates, ave_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate models\n",
    "@author: Ying Meng (y.meng201011(at)gmail(dot)com)\n",
    "\"\"\"\n",
    "def evaluating():\n",
    "    test_accuracies = []\n",
    "    ave_confs = []\n",
    "    ave_confs_misclassified = []\n",
    "    \n",
    "    # training models\n",
    "    for transformation in tqdm(M):\n",
    "        model_name = 'mnist_cnn_{}.h5'.format(transformation)\n",
    "        print(\"Evaluating model {}...\".format(model_name))\n",
    "        \n",
    "        _, (X_test, Y_test) = load_mnist()\n",
    "\n",
    "        if (transformation in M_ROTATE):\n",
    "            X_test = rotate(X_test, transformation)\n",
    "        elif (transformation in M_FLIP):\n",
    "            X_test = flip(X_test, transformation)\n",
    "        elif (transformation in M_SHIFT):\n",
    "            X_test = shift(X_test, transformation)\n",
    "        elif (transformation in M_AFFINE_TRANS):\n",
    "            X_test = affine_trans(X_test, transformation)\n",
    "        elif (transformation in M_MORPH_TRANS):\n",
    "            X_test = morph_trans(X_test, transformation)\n",
    "        elif (transformation in M_IMG_AUGMNT):\n",
    "            (X_test, Y_test) = augmentation(X_test, Y_test, transformation)\n",
    "        \n",
    "        # evaluate trained model\n",
    "        acc, conf, conf_misclassified = evaluate(model_name, X_test, Y_test)\n",
    "\n",
    "        test_accuracies.append(acc)\n",
    "        ave_confs.append(conf)\n",
    "        ave_confs_misclassified.append(conf_misclassified)\n",
    "\n",
    "    return test_accuracies, ave_confs, ave_confs_misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Automating experiments.\n",
    "# 1. train and save models\n",
    "# \n",
    "# You only need to run this once per model structure, dataset.\n",
    "# ---------------------------\n",
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Automating experiments.\n",
    "# 2. craft and save adversarial examples\n",
    "#\n",
    "# You only need to run this once per targeted model, attack approach.\n",
    "# ---------------------------\n",
    "crafting_adversarial_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Automating experiments.\n",
    "# 3. evaluate trained models\n",
    "# 4. evaluate attacks\n",
    "#\n",
    "# ---------------------------\n",
    "acc, confs, confs_misclassified = evaluating()\n",
    "acc_models, acc_adv, error_rates, confs_adv = evaluating_attacks()\n",
    "\n",
    "# print reports\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "df = pd.DataFrame(data = {\n",
    "    'Model': M,\n",
    "    'Acc(model)': acc,\n",
    "    'Conf(correct)': confs,\n",
    "    'Conf(miss)': confs_misclassified,\n",
    "    'Acc(fooled)': acc_adv,\n",
    "    'Conf(fooled)': confs_adv,\n",
    "    'Error Rate(eps = 0.25)': error_rates\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Automating experiments.\n",
    "# 5. export collected data to a csv file\n",
    "# 6. print the report\n",
    "#\n",
    "# ---------------------------\n",
    "df.to_csv('data/results.csv', sep=',', encoding='utf-8')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
